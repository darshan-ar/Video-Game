{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32])\n",
      "(30000, 32, 32)\n",
      "epoch [1/200], loss:-0.0051\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9056], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.8440], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.8436]], grad_fn=<SigmoidBackward>)\n",
      "epoch [2/200], loss:-0.0390\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.5931], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.7224], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.7138]], grad_fn=<SigmoidBackward>)\n",
      "epoch [3/200], loss:-0.1143\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.3157], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.3381], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.5259]], grad_fn=<SigmoidBackward>)\n",
      "epoch [4/200], loss:-0.2852\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9799], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9783], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.1546]], grad_fn=<SigmoidBackward>)\n",
      "epoch [5/200], loss:-0.3615\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9740], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9868], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0514]], grad_fn=<SigmoidBackward>)\n",
      "epoch [6/200], loss:-0.3983\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.0107], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0449], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0207]], grad_fn=<SigmoidBackward>)\n",
      "epoch [7/200], loss:-0.4124\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9975], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9981], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0111]], grad_fn=<SigmoidBackward>)\n",
      "epoch [8/200], loss:-0.4224\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.0055], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0055], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0065]], grad_fn=<SigmoidBackward>)\n",
      "epoch [9/200], loss:-0.4253\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.0021], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0063], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0040]], grad_fn=<SigmoidBackward>)\n",
      "epoch [10/200], loss:-0.4301\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.1438], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0023], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0029]], grad_fn=<SigmoidBackward>)\n",
      "epoch [11/200], loss:-0.4308\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.0018], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0018], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0019]], grad_fn=<SigmoidBackward>)\n",
      "epoch [12/200], loss:-0.4330\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.0014], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0017], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0013]], grad_fn=<SigmoidBackward>)\n",
      "epoch [13/200], loss:-0.4290\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.0009], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0008], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0010]], grad_fn=<SigmoidBackward>)\n",
      "epoch [14/200], loss:-0.4311\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9987], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9724], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0008]], grad_fn=<SigmoidBackward>)\n",
      "epoch [15/200], loss:-0.4319\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9993], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9961], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0007]], grad_fn=<SigmoidBackward>)\n",
      "epoch [16/200], loss:-0.4317\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.0005], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0006], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0006]], grad_fn=<SigmoidBackward>)\n",
      "epoch [17/200], loss:-0.4347\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9960], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9759], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0005]], grad_fn=<SigmoidBackward>)\n",
      "epoch [18/200], loss:-0.4356\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9999], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9995], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0004]], grad_fn=<SigmoidBackward>)\n",
      "epoch [19/200], loss:-0.4290\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.0004], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0004], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0004]], grad_fn=<SigmoidBackward>)\n",
      "epoch [20/200], loss:-0.4360\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9999], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0003]], grad_fn=<SigmoidBackward>)\n",
      "epoch [21/200], loss:-0.4345\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.0005], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0005], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0003]], grad_fn=<SigmoidBackward>)\n",
      "epoch [22/200], loss:-0.4352\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.0004], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0004], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "epoch [23/200], loss:-0.4358\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9999], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9997], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "epoch [24/200], loss:-0.4361\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0004], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "epoch [25/200], loss:-0.4368\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9849], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "epoch [26/200], loss:-0.4319\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "epoch [27/200], loss:-0.4369\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "epoch [28/200], loss:-0.4367\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "epoch [29/200], loss:-0.4363\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9999], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "epoch [30/200], loss:-0.4351\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[8.8742e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [31/200], loss:-0.4346\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9997], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[8.3846e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [32/200], loss:-0.4357\n",
      "torch.Size([1024])\n",
      "x:  tensor([4.5709e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[7.4274e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [33/200], loss:-0.4357\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9997], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[6.7358e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [34/200], loss:-0.4370\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[6.1781e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [35/200], loss:-0.4352\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9999], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[5.3589e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [36/200], loss:-0.4372\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.9358e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [37/200], loss:-0.4372\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9985], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.7062e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [38/200], loss:-0.4366\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.2942e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [39/200], loss:-0.4363\n",
      "torch.Size([1024])\n",
      "x:  tensor([5.2367e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([4.3850e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.8079e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [40/200], loss:-0.4338\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9999], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.5401e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [41/200], loss:-0.4367\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.1884e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [42/200], loss:-0.4353\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9999], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.8741e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [43/200], loss:-0.4372\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.7023e-05]], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [44/200], loss:-0.4369\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.5252e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [45/200], loss:-0.4355\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9999], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.2247e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [46/200], loss:-0.4333\n",
      "torch.Size([1024])\n",
      "x:  tensor([4.8247e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.6148e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.1060e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [47/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9999], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9631e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [48/200], loss:-0.4339\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.8472e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [49/200], loss:-0.4374\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6747e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [50/200], loss:-0.4345\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.9551e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.6373e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5205e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [51/200], loss:-0.4370\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.4248e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [52/200], loss:-0.4372\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9999], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9999], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.3708e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [53/200], loss:-0.4313\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.2654e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [54/200], loss:-0.4374\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.2091e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [55/200], loss:-0.4374\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.0986e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [56/200], loss:-0.4372\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[9.9895e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [57/200], loss:-0.4368\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.1106e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[9.3899e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [58/200], loss:-0.4363\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0890e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.0364e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[8.6932e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [59/200], loss:-0.4355\n",
      "torch.Size([1024])\n",
      "x:  tensor([0.9997], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[8.2058e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [60/200], loss:-0.4346\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[7.7774e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [61/200], loss:-0.4340\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[7.2412e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [62/200], loss:-0.4366\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[6.7469e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [63/200], loss:-0.4351\n",
      "torch.Size([1024])\n",
      "x:  tensor([3.0405e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([4.4684e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[6.4140e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [64/200], loss:-0.4374\n",
      "torch.Size([1024])\n",
      "x:  tensor([3.0794e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.2650e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[5.9872e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [65/200], loss:-0.4374\n",
      "torch.Size([1024])\n",
      "x:  tensor([8.6483e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([5.5892e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[5.7272e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [66/200], loss:-0.4355\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9999], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[5.3052e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [67/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([7.7365e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([5.0025e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[5.1135e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [68/200], loss:-0.4374\n",
      "torch.Size([1024])\n",
      "x:  tensor([5.1346e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([5.8761e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.8679e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [69/200], loss:-0.4340\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.4439e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [70/200], loss:-0.4374\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.3613e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [71/200], loss:-0.4374\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.0841e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [72/200], loss:-0.4313\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.0145e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [73/200], loss:-0.4351\n",
      "torch.Size([1024])\n",
      "x:  tensor([3.3475e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.2319e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.7018e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [74/200], loss:-0.4351\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.5623e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [75/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([3.8366e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.4460e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.3792e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [76/200], loss:-0.4334\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.1905e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [77/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.1216e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [78/200], loss:-0.4363\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.0033e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [79/200], loss:-0.4355\n",
      "torch.Size([1024])\n",
      "x:  tensor([7.8793e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([9.6725e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.8954e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [80/200], loss:-0.4334\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.7501e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [81/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.9281e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.6774e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.7337e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [82/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([5.2613e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([7.5694e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.5894e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [83/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.5460e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [84/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.4861e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [85/200], loss:-0.4369\n",
      "torch.Size([1024])\n",
      "x:  tensor([4.1882e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([6.2580e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.4142e-06]], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [86/200], loss:-0.4371\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.3382e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [87/200], loss:-0.4366\n",
      "torch.Size([1024])\n",
      "x:  tensor([3.0079e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([4.1138e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.2495e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [88/200], loss:-0.4369\n",
      "torch.Size([1024])\n",
      "x:  tensor([4.6091e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.6370e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.2593e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [89/200], loss:-0.4371\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.7226e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([7.1685e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.1883e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [90/200], loss:-0.4351\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.8129e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([4.8391e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.1297e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [91/200], loss:-0.4334\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.1423e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [92/200], loss:-0.4355\n",
      "torch.Size([1024])\n",
      "x:  tensor([4.0490e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([7.6529e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.0755e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [93/200], loss:-0.4355\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.0790e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [94/200], loss:-0.4321\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9970e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [95/200], loss:-0.4369\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.0518e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [96/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.0509e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [97/200], loss:-0.4371\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.0252e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [98/200], loss:-0.4360\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.7571e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([4.3641e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9926e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [99/200], loss:-0.4374\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.9891e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.7888e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9883e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [100/200], loss:-0.4371\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.0049e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [101/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9760e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [102/200], loss:-0.4366\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.0804e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [103/200], loss:-0.4369\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9772e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [104/200], loss:-0.4371\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9963e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [105/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9835e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [106/200], loss:-0.4247\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9674e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [107/200], loss:-0.4360\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.6793e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.5769e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.0181e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [108/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.8029e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.3947e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9813e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [109/200], loss:-0.4363\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9619e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [110/200], loss:-0.4366\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9706e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [111/200], loss:-0.4369\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9917e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [112/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9995], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9120e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [113/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.9328e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.4024e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9458e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [114/200], loss:-0.4374\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9678e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [115/200], loss:-0.4371\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9301e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [116/200], loss:-0.4313\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.7071e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.5265e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9030e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [117/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9072e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [118/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([4.2312e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.3555e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9257e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [119/200], loss:-0.4366\n",
      "torch.Size([1024])\n",
      "x:  tensor([3.1747e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.6970e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.8759e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [120/200], loss:-0.4374\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.8648e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [121/200], loss:-0.4328\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.8732e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [122/200], loss:-0.4328\n",
      "torch.Size([1024])\n",
      "x:  tensor([6.1710e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.9077e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.8708e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [123/200], loss:-0.4340\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.8144e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [124/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.8724e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [125/200], loss:-0.4371\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.5142e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.9350e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.8584e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [126/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.2208e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.7078e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.8333e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [127/200], loss:-0.4371\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.7735e-06]], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [128/200], loss:-0.4360\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.3535e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.4050e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.7676e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [129/200], loss:-0.4360\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.7462e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [130/200], loss:-0.4351\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.6015e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.1389e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.7452e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [131/200], loss:-0.4346\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.7172e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [132/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.7724e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [133/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.7176e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [134/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.7108e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [135/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.8113e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [136/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.7287e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [137/200], loss:-0.4351\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.7224e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [138/200], loss:-0.4366\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.5379e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.1219e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6708e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [139/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6850e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [140/200], loss:-0.4340\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6977e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [141/200], loss:-0.4351\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.4385e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.9959e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6844e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [142/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6760e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [143/200], loss:-0.4279\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.5040e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.8399e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6365e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [144/200], loss:-0.4355\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.7043e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [145/200], loss:-0.4363\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.8644e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.2212e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6037e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [146/200], loss:-0.4369\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6345e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [147/200], loss:-0.4366\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.4546e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.5896e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6151e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [148/200], loss:-0.4371\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.2451e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.8873e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6646e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [149/200], loss:-0.4334\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6728e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [150/200], loss:-0.4313\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.1895e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.4336e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5636e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [151/200], loss:-0.4369\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5986e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [152/200], loss:-0.4363\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.2304e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.0086e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5783e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [153/200], loss:-0.4360\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.2214e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.5666e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6499e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [154/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.6395e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.0343e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6670e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [155/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.5186e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([7.6175e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6137e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [156/200], loss:-0.4371\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6215e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [157/200], loss:-0.4366\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6566e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [158/200], loss:-0.4366\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6379e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [159/200], loss:-0.4297\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.8694e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.6444e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5228e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [160/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.4682e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [161/200], loss:-0.4363\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5677e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [162/200], loss:-0.4369\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6885e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [163/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([4.2030e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.5624e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5306e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [164/200], loss:-0.4371\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.0166e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([4.8371e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6610e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [165/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6044e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [166/200], loss:-0.4351\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.0742e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.0279e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6441e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [167/200], loss:-0.4334\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6751e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [168/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.2219e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.8645e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.7852e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [169/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([4.0428e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.7501e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6811e-06]], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [170/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.4994e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.4241e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6520e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [171/200], loss:-0.4369\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.7624e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.9793e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6131e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [172/200], loss:-0.4374\n",
      "torch.Size([1024])\n",
      "x:  tensor([3.2973e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.5811e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.7555e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [173/200], loss:-0.4371\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5339e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [174/200], loss:-0.4360\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.2879e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.6781e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6687e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [175/200], loss:-0.4374\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.3910e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [176/200], loss:-0.4363\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.4486e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.2091e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5594e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [177/200], loss:-0.4279\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6359e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [178/200], loss:-0.4366\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.3753e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [179/200], loss:-0.4363\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.5019e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.5313e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5458e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [180/200], loss:-0.4321\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5298e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [181/200], loss:-0.4346\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0818e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.9131e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5521e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [182/200], loss:-0.4313\n",
      "torch.Size([1024])\n",
      "x:  tensor([7.2676e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.1736e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5881e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [183/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.8192e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.8178e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5266e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [184/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.3388e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.5214e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6056e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [185/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.4788e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [186/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.4743e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [187/200], loss:-0.4374\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6100e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [188/200], loss:-0.4363\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.6663e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.6922e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5479e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [189/200], loss:-0.4334\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.8940e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.0693e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5400e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [190/200], loss:-0.4313\n",
      "torch.Size([1024])\n",
      "x:  tensor([3.8596e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.4069e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.4324e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [191/200], loss:-0.4375\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.3169e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.0629e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5135e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [192/200], loss:-0.4371\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.3752e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.5657e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.3501e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [193/200], loss:-0.4371\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9999], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5248e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [194/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6329e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [195/200], loss:-0.4366\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.4609e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [196/200], loss:-0.4373\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5195e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [197/200], loss:-0.4371\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6125e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [198/200], loss:-0.4351\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5149e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [199/200], loss:-0.4321\n",
      "torch.Size([1024])\n",
      "x:  tensor([2.0728e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.4421e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.3754e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [200/200], loss:-0.4369\n",
      "torch.Size([1024])\n",
      "x:  tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0000], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5915e-06]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.utils.data as Data\n",
    "from PIL import  Image,ImageDraw\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "Batch_Size = 250\n",
    "num_epochs = 200\n",
    "learning_rate = 1e-5\n",
    "samples = 30000\n",
    "\n",
    "data1 = []\n",
    "data2= []\n",
    "\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% --  Generate dataset\n",
    "\n",
    "\n",
    "for i in range(samples):\n",
    "    \n",
    "    switch = random.randint(0,1)\n",
    "    if switch==0:\n",
    "        img = Image.new('RGB', (32, 32), color = 'white')\n",
    "        row,col,ch= np.shape(img)\n",
    "        mean = random.randint(1,6)\n",
    "        var = random.random()\n",
    "        sigma = var**0.5\n",
    "        gauss_pos1 = np.random.normal(mean,sigma,(row,col,ch))\n",
    "        noisy_pos1 = img + gauss_pos1\n",
    "        im2_pos1 = Image.fromarray(noisy_pos1,'RGB')\n",
    "        draw = ImageDraw.Draw(im2_pos1)\n",
    "        draw.rectangle([9,12,12,15],fill='red',outline='red')\n",
    "        data1.append(np.asarray(im2_pos1))\n",
    "\n",
    "        img_1 = Image.new('RGB',  (32, 32), color = 'white')\n",
    "        row_1,col_1,ch_1= np.shape(img_1)\n",
    "        mean_1 = random.randint(1,6)\n",
    "        var_1 = random.random()\n",
    "        sigma_1 = var_1**0.5\n",
    "        gauss_pos2 = np.random.normal(mean_1,sigma_1,(row_1,col_1,ch_1))\n",
    "        noisy_pos2 = img_1 + gauss_pos2\n",
    "        im2_pos2 = Image.fromarray(noisy_pos2,'RGB')\n",
    "        draw_1 = ImageDraw.Draw(im2_pos2)\n",
    "        draw_1.rectangle([21, 12, 24, 15], fill='red', outline='red')\n",
    "        data2.append(np.asarray(im2_pos2))\n",
    "    elif switch==1:\n",
    "        img_blank = Image.new('RGB',  (32, 32), color = 'white')\n",
    "        row_blank,col_blank,ch_blank= np.shape(img_blank)\n",
    "        mean_blank = random.randint(1,6)\n",
    "        var_blank = random.random()\n",
    "        sigma_blank = var_blank**0.5\n",
    "        gauss_blank_pos1 = np.random.normal(mean_blank,sigma_blank,(row_blank,col_blank,ch_blank))\n",
    "        noisy_blank_pos1 = img_blank + gauss_blank_pos1\n",
    "        im2_blank_pos1 = Image.fromarray(noisy_blank_pos1,'RGB')\n",
    "        data1.append(np.asarray(im2_blank_pos1))\n",
    "\n",
    "        img_blank_1 = Image.new('RGB', (32, 32), color = 'white')\n",
    "        row_blank_1,col_blank_1,ch_blank_1= np.shape(img_blank_1)\n",
    "        mean_blank_1 = random.randint(1,6)\n",
    "        var_blank_1 = random.random()\n",
    "        sigma_blank_1 = var_blank_1**0.5\n",
    "        gauss_blank_pos2 = np.random.normal(mean_blank_1,sigma_blank_1,(row_blank_1,col_blank_1,ch_blank_1))\n",
    "        noisy_blank_pos2 = img_blank_1 + gauss_blank_pos2\n",
    "        im2_blank_pos2 = Image.fromarray(noisy_blank_pos2,'RGB')\n",
    "        data2.append(np.asarray(im2_blank_pos2))\n",
    "\n",
    "\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%% Noisy data\n",
    "img = Image.new('RGB',  (32, 32), color = 'white')\n",
    "row,col,ch= np.shape(img)\n",
    "mean = random.randint(1,6)\n",
    "var = random.random()\n",
    "sigma = var**0.5\n",
    "gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "noisy = img + gauss\n",
    "im2 = Image.fromarray(noisy,'RGB')\n",
    "b = np.asarray(im2)\n",
    "b = np.array(b, dtype=np.float32)\n",
    "b=b[:,:,0]\n",
    "b = torch.from_numpy(b)\n",
    "print(np.shape(b))\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%       \n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% - Data Preparation\n",
    "\n",
    "y0 = np.array(data1, dtype=np.float32)\n",
    "y1 = np.array(data2, dtype=np.float32)\n",
    "y0 = y0[:,:,:,0]\n",
    "y1 = y1[:,:,:,0]\n",
    "\n",
    "print(y0.shape)\n",
    "\n",
    "x = torch.from_numpy(y0)\n",
    "y = torch.from_numpy(y1)\n",
    "\n",
    "\n",
    "torch_dataset = Data.TensorDataset(x,y)\n",
    "\n",
    "\n",
    "loader = Data.DataLoader(\n",
    "\n",
    "    dataset=torch_dataset,\n",
    "\n",
    "    batch_size=Batch_Size,\n",
    "\n",
    "    shuffle=True,\n",
    "\n",
    "    num_workers=0,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% - Defining NN\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder_hidden_layer = nn.Linear(\n",
    "            in_features=kwargs[\"input_shape\"], out_features=128\n",
    "        )\n",
    "        self.encoder_output_layer = nn.Linear(\n",
    "            in_features=128, out_features=64\n",
    "        )\n",
    "        self.encoder_output_layer_1 = nn.Linear(\n",
    "            in_features=64, out_features=32\n",
    "        )\n",
    "        self.encoder_output_layer_2 = nn.Linear(\n",
    "            in_features=32, out_features=16\n",
    "        )\n",
    "        self.encoder_output_layer_3 = nn.Linear(\n",
    "            in_features=16, out_features=8\n",
    "        )\n",
    "        self.encoder_output_layer_4 = nn.Linear(\n",
    "            in_features=8, out_features=1\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, features):\n",
    "        activation = self.encoder_hidden_layer(features)\n",
    "        activation = torch.relu(activation)\n",
    "        code = self.encoder_output_layer(activation)\n",
    "        code = torch.relu(code)\n",
    "        code = self.encoder_output_layer_1(code)\n",
    "        code = torch.relu(code)\n",
    "        code = self.encoder_output_layer_2(code)\n",
    "        code = torch.relu(code)\n",
    "        code = self.encoder_output_layer_3(code)\n",
    "        code = torch.relu(code)\n",
    "        code = self.encoder_output_layer_4(code)\n",
    "        code = torch.sigmoid(code)\n",
    "        return code\n",
    "\n",
    "#  use gpu if available\n",
    "\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "model = AE(input_shape=1024)\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% - Loss Function\n",
    "\n",
    "def h_score(fx, gy):\n",
    " \n",
    "    fx = fx - fx.mean(0)\n",
    "\n",
    "    gy = gy - gy.mean(0)\n",
    "\n",
    "    Nsamples = fx.size(0)\n",
    "\n",
    "    covf = torch.matmul((fx.t()), fx) / Nsamples\n",
    "\n",
    "    covg = torch.matmul((gy.t()), (gy)) / Nsamples\n",
    "\n",
    "    h = -2 * torch.mean((fx * gy).sum(1)) + (covf * covg).sum()\n",
    "\n",
    "    return h\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for x,y in loader:\n",
    "        optimizer.zero_grad()\n",
    "        # ===================forward=====================\n",
    "        #loss = criterion(output1, img)\n",
    "        x = x.view(-1, 1024)\n",
    "        y = y.view(-1, 1024)\n",
    "        loss = h_score(model(x),model(y))\n",
    "        # ===================backward====================\n",
    "\n",
    "        #optimizer_1.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #optimizer_1.step()\n",
    "    # ===================log========================\n",
    "    b = b.view(-1,1024)\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "    print(np.shape(x[0]))\n",
    "    print(\"x: \", model(x[0]))\n",
    "    print(\"y:\", model(y[0]))\n",
    "    print(\"b:\", model(b))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([[1.0000]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([[1.0000]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([[1.0000]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([[1.0000]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([[1.0000]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "data3=[]\n",
    "\n",
    "for i in range(5):\n",
    "    img = Image.new('RGB', (28, 28), color = 'white')\n",
    "    row,col,ch= np.shape(img)\n",
    "    mean = random.randint(1,6)\n",
    "    var = random.random()\n",
    "    sigma = var**0.5\n",
    "    gauss_pos1 = np.random.normal(mean,sigma,(row,col,ch))\n",
    "    noisy_pos1 = img + gauss_pos1\n",
    "    im2_pos1 = Image.fromarray(noisy_pos1,'RGB')\n",
    "    draw = ImageDraw.Draw(im2_pos1)\n",
    "    draw.rectangle([9,12,12,15],fill='red',outline='red')\n",
    "    data3.append(np.asarray(im2_pos1))\n",
    "\n",
    "    y3 = np.array(data3, dtype=np.float32)\n",
    "    #y1 = np.array(data2, dtype=np.float32)\n",
    "    y3 = y3[:,:,:,0]\n",
    "    #y1 = y1[:,:,:,0]\n",
    "    x_1 = torch.from_numpy(y3)\n",
    "    print(\"x: \", model(x_1[i].view(-1,784)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
