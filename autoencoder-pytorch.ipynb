{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "epochs = 20\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 32, 32, 3)\n",
      "(20000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "data1 = cv2.imread('pos1_32x32.png')\n",
    "data2= cv2.imread('pos2_32x32.png')\n",
    "\n",
    "result = np.repeat(data1[np.newaxis,...], 20000, axis=0)\n",
    "print(result.shape)\n",
    "y0 = result.astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result1 = np.repeat(data2[np.newaxis,...], 20000, axis=0)\n",
    "y1 = result1.astype('float32')\n",
    "\n",
    "y0 = y0[:,:,:,0]\n",
    "y1 = y1[:,:,:,0]\n",
    "print(y0.shape)\n",
    "\n",
    "x = torch.from_numpy(y0)\n",
    "y = torch.from_numpy(y1)\n",
    "\n",
    "\n",
    "\n",
    "torch_dataset = Data.TensorDataset(x,y)\n",
    "\n",
    "\n",
    "loader = Data.DataLoader(\n",
    "\n",
    "    dataset=torch_dataset,\n",
    "\n",
    "    batch_size=250,\n",
    "\n",
    "    shuffle=True,\n",
    "\n",
    "    num_workers=0,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder_hidden_layer = nn.Linear(\n",
    "            in_features=kwargs[\"input_shape\"], out_features=128\n",
    "        )\n",
    "        self.encoder_output_layer = nn.Linear(\n",
    "            in_features=128, out_features=64\n",
    "        )\n",
    "        self.encoder_output_layer_1 = nn.Linear(\n",
    "            in_features=64, out_features=32\n",
    "        )\n",
    "        self.encoder_output_layer_2 = nn.Linear(\n",
    "            in_features=32, out_features=16\n",
    "        )\n",
    "        self.encoder_output_layer_3 = nn.Linear(\n",
    "            in_features=16, out_features=8\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, features):\n",
    "        activation = self.encoder_hidden_layer(features)\n",
    "        activation = torch.relu(activation)\n",
    "        code = self.encoder_output_layer(activation)\n",
    "        code = torch.relu(code)\n",
    "        code = self.encoder_output_layer_1(code)\n",
    "        code = torch.relu(code)\n",
    "        code = self.encoder_output_layer_2(code)\n",
    "        code = torch.relu(code)\n",
    "        code = self.encoder_output_layer_3(code)\n",
    "        code = torch.sigmoid(code)\n",
    "        return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  use gpu if available\n",
    "\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "model = AE(input_shape=1024)\n",
    "\n",
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# mean-squared error loss\n",
    "def h_score(fx, gy):\n",
    " \n",
    "    fx = fx - fx.mean(0)\n",
    "\n",
    "    gy = gy - gy.mean(0)\n",
    "\n",
    "    Nsamples = fx.size(0)\n",
    "\n",
    "    covf = torch.matmul((fx.t()), fx) / Nsamples\n",
    "\n",
    "    covg = torch.matmul((gy.t()), (gy)) / Nsamples\n",
    "\n",
    "    h = -2 * torch.mean((fx * gy).sum(1)) + (covf * covg).sum()\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/20, recon loss = 0.00000000\n",
      "epoch : 2/20, recon loss = -0.00000000\n",
      "epoch : 3/20, recon loss = 0.00000000\n",
      "epoch : 4/20, recon loss = 0.00000000\n",
      "epoch : 5/20, recon loss = 0.00000000\n",
      "epoch : 6/20, recon loss = 0.00000000\n",
      "epoch : 7/20, recon loss = -0.00000000\n",
      "epoch : 8/20, recon loss = -0.00000000\n",
      "epoch : 9/20, recon loss = -0.00000000\n",
      "epoch : 10/20, recon loss = 0.00000000\n",
      "epoch : 11/20, recon loss = 0.00000000\n",
      "epoch : 12/20, recon loss = 0.00000000\n",
      "epoch : 13/20, recon loss = 0.00000000\n",
      "epoch : 14/20, recon loss = -0.00000000\n",
      "epoch : 15/20, recon loss = 0.00000000\n",
      "epoch : 16/20, recon loss = 0.00000000\n",
      "epoch : 17/20, recon loss = 0.00000000\n",
      "epoch : 18/20, recon loss = -0.00000000\n",
      "epoch : 19/20, recon loss = -0.00000000\n",
      "epoch : 20/20, recon loss = -0.00000000\n",
      "epoch : 21/20, recon loss = -0.00000000\n",
      "epoch : 22/20, recon loss = 0.00000000\n",
      "epoch : 23/20, recon loss = -0.00000000\n",
      "epoch : 24/20, recon loss = -0.00000000\n",
      "epoch : 25/20, recon loss = -0.00000000\n",
      "epoch : 26/20, recon loss = -0.00000000\n",
      "epoch : 27/20, recon loss = -0.00000000\n",
      "epoch : 28/20, recon loss = -0.00000000\n",
      "epoch : 29/20, recon loss = -0.00000000\n",
      "epoch : 30/20, recon loss = -0.00000000\n",
      "epoch : 31/20, recon loss = -0.00000000\n",
      "epoch : 32/20, recon loss = -0.00000000\n",
      "epoch : 33/20, recon loss = -0.00000000\n",
      "epoch : 34/20, recon loss = -0.00000000\n",
      "epoch : 35/20, recon loss = -0.00000000\n",
      "epoch : 36/20, recon loss = -0.00000000\n",
      "epoch : 37/20, recon loss = -0.00000000\n",
      "epoch : 38/20, recon loss = -0.00000000\n",
      "epoch : 39/20, recon loss = -0.00000000\n",
      "epoch : 40/20, recon loss = -0.00000000\n",
      "epoch : 41/20, recon loss = -0.00000000\n",
      "epoch : 42/20, recon loss = -0.00000000\n",
      "epoch : 43/20, recon loss = 0.00000000\n",
      "epoch : 44/20, recon loss = 0.00000000\n",
      "epoch : 45/20, recon loss = 0.00000000\n",
      "epoch : 46/20, recon loss = 0.00000000\n",
      "epoch : 47/20, recon loss = -0.00000000\n",
      "epoch : 48/20, recon loss = -0.00000000\n",
      "epoch : 49/20, recon loss = -0.00000000\n",
      "epoch : 50/20, recon loss = -0.00000000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    loss = 0\n",
    "    for x,y in loader:\n",
    "        # reshape mini-batch data to [N, 784] matrix\n",
    "        # load it to the active device\n",
    "        #print(batch_features[0].shape)\n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    "        optimizer.zero_grad()\n",
    "        x = x.view(-1, 1024)\n",
    "        y = y.view(-1, 1024)\n",
    "        # compute reconstructions        \n",
    "        # compute training reconstruction loss\n",
    "        train_loss = h_score(model(x),model(y))\n",
    "        \n",
    "        # compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss += train_loss.item()\n",
    "    \n",
    "    # compute the epoch training loss\n",
    "    loss = loss / len(train_loader)\n",
    "    \n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, recon loss = {:.8f}\".format(epoch + 1, epochs, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    x, batch_size=200, shuffle=True\n",
    ")\n",
    "\n",
    "test_examples = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features in test_loader:\n",
    "        test_examples = batch_features.view(-1, 1024)\n",
    "        reconstruction = model(test_examples)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "Let's try to reconstruct some test images using our trained autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    number = 10\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for index in range(number):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, number, index + 1)\n",
    "        plt.imshow(y0[index])\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, number, index + 1 + number)\n",
    "        plt.imshow(reconstruction[index].numpy().reshape(2,4 ))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
