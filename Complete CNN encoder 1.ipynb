{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/100, recon loss = -0.00002365\n",
      "epoch : 2/100, recon loss = 0.00020252\n",
      "epoch : 3/100, recon loss = -0.00017057\n",
      "epoch : 4/100, recon loss = -0.00009494\n",
      "epoch : 5/100, recon loss = -0.00066796\n",
      "epoch : 6/100, recon loss = -0.00921049\n",
      "epoch : 7/100, recon loss = -0.10014464\n",
      "epoch : 8/100, recon loss = -0.35598918\n",
      "epoch : 9/100, recon loss = -0.60739362\n",
      "epoch : 10/100, recon loss = -0.73042363\n",
      "epoch : 11/100, recon loss = -0.80245209\n",
      "epoch : 12/100, recon loss = -0.83976209\n",
      "epoch : 13/100, recon loss = -0.84654919\n",
      "epoch : 14/100, recon loss = -0.86663714\n",
      "epoch : 15/100, recon loss = -0.88098449\n",
      "epoch : 16/100, recon loss = -0.88396214\n",
      "epoch : 17/100, recon loss = -0.88787583\n",
      "epoch : 18/100, recon loss = -0.89451275\n",
      "epoch : 19/100, recon loss = -0.89702724\n",
      "epoch : 20/100, recon loss = -0.90332046\n",
      "epoch : 21/100, recon loss = -0.90130295\n",
      "epoch : 22/100, recon loss = -0.89995291\n",
      "epoch : 23/100, recon loss = -0.90901962\n",
      "epoch : 24/100, recon loss = -0.90964098\n",
      "epoch : 25/100, recon loss = -0.91455131\n",
      "epoch : 26/100, recon loss = -0.91423669\n",
      "epoch : 27/100, recon loss = -0.91807607\n",
      "epoch : 28/100, recon loss = -0.91665117\n",
      "epoch : 29/100, recon loss = -0.91761377\n",
      "epoch : 30/100, recon loss = -0.92311429\n",
      "epoch : 31/100, recon loss = -0.91067864\n",
      "epoch : 32/100, recon loss = -0.92438188\n",
      "epoch : 33/100, recon loss = -0.92568399\n",
      "epoch : 34/100, recon loss = -0.91966446\n",
      "epoch : 35/100, recon loss = -0.92840060\n",
      "epoch : 36/100, recon loss = -0.92399968\n",
      "epoch : 37/100, recon loss = -0.92552354\n",
      "epoch : 38/100, recon loss = -0.92669668\n",
      "epoch : 39/100, recon loss = -0.92856031\n",
      "epoch : 40/100, recon loss = -0.92984647\n",
      "epoch : 41/100, recon loss = -0.92746173\n",
      "epoch : 42/100, recon loss = -0.92955884\n",
      "epoch : 43/100, recon loss = -0.93465885\n",
      "epoch : 44/100, recon loss = -0.93499108\n",
      "epoch : 45/100, recon loss = -0.93388801\n",
      "epoch : 46/100, recon loss = -0.93568952\n",
      "epoch : 47/100, recon loss = -0.93803381\n",
      "epoch : 48/100, recon loss = -0.93831024\n",
      "epoch : 49/100, recon loss = -0.94000756\n",
      "epoch : 50/100, recon loss = -0.94233380\n",
      "epoch : 51/100, recon loss = -0.94413051\n",
      "epoch : 52/100, recon loss = -0.94617606\n",
      "epoch : 53/100, recon loss = -0.95124604\n",
      "epoch : 54/100, recon loss = -0.95564832\n",
      "epoch : 55/100, recon loss = -0.95629975\n",
      "epoch : 56/100, recon loss = -0.96339691\n",
      "epoch : 57/100, recon loss = -0.96459108\n",
      "epoch : 58/100, recon loss = -0.96575762\n",
      "epoch : 59/100, recon loss = -0.96939765\n",
      "epoch : 60/100, recon loss = -0.96914822\n",
      "epoch : 61/100, recon loss = -0.95866195\n",
      "epoch : 62/100, recon loss = -0.93901004\n",
      "epoch : 63/100, recon loss = -0.94682042\n",
      "epoch : 64/100, recon loss = -0.94875845\n",
      "epoch : 65/100, recon loss = -0.94229983\n",
      "epoch : 66/100, recon loss = -0.94072264\n",
      "epoch : 67/100, recon loss = -0.94594235\n",
      "epoch : 68/100, recon loss = -0.95093598\n",
      "epoch : 69/100, recon loss = -0.95547372\n",
      "epoch : 70/100, recon loss = -0.96470569\n",
      "epoch : 71/100, recon loss = -0.96679076\n",
      "epoch : 72/100, recon loss = -0.96822232\n",
      "epoch : 73/100, recon loss = -0.97516461\n",
      "epoch : 74/100, recon loss = -0.97402589\n",
      "epoch : 75/100, recon loss = -0.97352402\n",
      "epoch : 76/100, recon loss = -0.97535716\n",
      "epoch : 77/100, recon loss = -0.97294705\n",
      "epoch : 78/100, recon loss = -0.97646665\n",
      "epoch : 79/100, recon loss = -0.97301672\n",
      "epoch : 80/100, recon loss = -0.96899177\n",
      "epoch : 81/100, recon loss = -0.97366612\n",
      "epoch : 82/100, recon loss = -0.97136931\n",
      "epoch : 83/100, recon loss = -0.96883643\n",
      "epoch : 84/100, recon loss = -0.96742471\n",
      "epoch : 85/100, recon loss = -0.97514250\n",
      "epoch : 86/100, recon loss = -0.98131690\n",
      "epoch : 87/100, recon loss = -0.98107328\n",
      "epoch : 88/100, recon loss = -0.97413290\n",
      "epoch : 89/100, recon loss = -0.97420733\n",
      "epoch : 90/100, recon loss = -0.97202602\n",
      "epoch : 91/100, recon loss = -0.97145843\n",
      "epoch : 92/100, recon loss = -0.97688895\n",
      "epoch : 93/100, recon loss = -0.97816537\n",
      "epoch : 94/100, recon loss = -0.98149805\n",
      "epoch : 95/100, recon loss = -0.97610857\n",
      "epoch : 96/100, recon loss = -0.97826771\n",
      "epoch : 97/100, recon loss = -0.97718346\n",
      "epoch : 98/100, recon loss = -0.97756315\n",
      "epoch : 99/100, recon loss = -0.97832564\n",
      "epoch : 100/100, recon loss = -0.97641743\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.utils.data as Data\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "epochs= 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "from PIL import  Image,ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data1 = []\n",
    "data2= []\n",
    "\n",
    "for i in range(20000):\n",
    "    img = Image.new('RGB', (32, 32), color = 'white')\n",
    "\n",
    "    row,col,ch= np.shape(img)\n",
    "    mean = 0\n",
    "    var = 1\n",
    "    sigma = var**0.5\n",
    "    gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "    noisy = img + gauss\n",
    "    im2 = Image.fromarray(noisy,'RGB')\n",
    "\n",
    "    draw = ImageDraw.Draw(im2)\n",
    "\n",
    "    draw.rectangle([21,12,24,15],fill='red',outline='red')\n",
    "    data2.append(np.asarray(im2))\n",
    "\n",
    "\n",
    "for i in range(20000):\n",
    "    img = Image.new('RGB', (32, 32), color = 'white')\n",
    "\n",
    "\n",
    "    row,col,ch= np.shape(img)\n",
    "    mean = 0\n",
    "    var = 1\n",
    "    sigma = var**0.5\n",
    "    gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "    noisy = img + gauss\n",
    "    im2 = Image.fromarray(noisy,'RGB')\n",
    "\n",
    "    draw = ImageDraw.Draw(im2)\n",
    "\n",
    "    draw.rectangle([9,12,12,15],fill='red',outline='red')\n",
    "    data1.append(np.asarray(im2))\n",
    "    \n",
    "\n",
    "y0 = np.array(data1, dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y1 = np.array(data2, dtype=np.float32)\n",
    "y0 = np.transpose(y0, (0, 3, 2, 1))# This to make channels first for CNN\n",
    "y1 = np.transpose(y1, (0, 3, 2, 1)) \n",
    "\n",
    "x = torch.from_numpy(y0)\n",
    "y = torch.from_numpy(y1)\n",
    "\n",
    "\n",
    "\n",
    "torch_dataset = Data.TensorDataset(x,y)\n",
    "\n",
    "\n",
    "loader = Data.DataLoader(\n",
    "\n",
    "    dataset=torch_dataset,\n",
    "\n",
    "    batch_size=250,\n",
    "\n",
    "    shuffle=True,\n",
    "\n",
    "    num_workers=0,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"CNN.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv_layer = nn.Sequential(\n",
    "\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv Layer block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(p=0.05),\n",
    "\n",
    "            # Conv Layer block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "        \n",
    "        # conv layers\n",
    "        x = self.conv_layer(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # fc layer\n",
    "        x = self.fc_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "#  use gpu if available\n",
    "\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "model = CNN()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "# mean-squared error loss\n",
    "def h_score(fx, gy):\n",
    " \n",
    "    fx = fx - fx.mean(0)\n",
    "\n",
    "    gy = gy - gy.mean(0)\n",
    "\n",
    "    Nsamples = fx.size(0)\n",
    "\n",
    "    covf = torch.matmul((fx.t()), fx) / Nsamples\n",
    "\n",
    "    covg = torch.matmul((gy.t()), (gy)) / Nsamples\n",
    "\n",
    "    h = -2 * torch.mean((fx * gy).sum(1)) + (covf * covg).sum()\n",
    "\n",
    "    return h\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for x,y in loader:\n",
    "        # reshape mini-batch data to [N, 784] matrix\n",
    "        # load it to the active device\n",
    "        #print(batch_features[0].shape)\n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    "        optimizer.zero_grad()\n",
    "        # compute reconstructions        \n",
    "        # compute training reconstruction loss\n",
    "        train_loss = h_score(model(x),model(y))\n",
    "        #train_loss = criterion(model(x),model(y))\n",
    "        # compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss += train_loss.item()\n",
    "    \n",
    "    # compute the epoch training loss\n",
    "    loss = loss / len(loader)\n",
    "    \n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, recon loss = {:.8f}\".format(epoch + 1, epochs,loss))\n",
    "    #print(np.shape(model.encoder_hidden_layer.weight.data),np.shape(model_dec.decoder_output_layer.weight.data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = cv2.imread('blank_28x28.png')\n",
    "b = blank.astype('float32')\n",
    "b = torch.from_numpy(b)\n",
    "\n",
    "for i in range(5,15):\n",
    "    print(\"x: \", model(x[i].reshape(1,3,28,28)))\n",
    "    print(\"y:\", model(y[i].reshape(1,3,28,28)))\n",
    "\n",
    "print(\"b:\", model(b.reshape(1,3,28,28)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
