{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 3)\n",
      "(60000, 3, 28, 28)\n",
      "epoch [1/100], loss:0.0000\n",
      "epoch [2/100], loss:0.0000\n",
      "epoch [3/100], loss:0.0000\n",
      "epoch [4/100], loss:0.0000\n",
      "epoch [5/100], loss:0.0000\n",
      "epoch [6/100], loss:0.0000\n",
      "epoch [7/100], loss:0.0000\n",
      "epoch [8/100], loss:0.0000\n",
      "epoch [9/100], loss:0.0000\n",
      "epoch [10/100], loss:0.0000\n",
      "epoch [11/100], loss:0.0000\n",
      "epoch [12/100], loss:0.0000\n",
      "epoch [13/100], loss:0.0000\n",
      "epoch [14/100], loss:0.0000\n",
      "epoch [15/100], loss:0.0000\n",
      "epoch [16/100], loss:0.0000\n",
      "epoch [17/100], loss:0.0000\n",
      "epoch [18/100], loss:0.0000\n",
      "epoch [19/100], loss:0.0000\n",
      "epoch [20/100], loss:0.0000\n",
      "epoch [21/100], loss:0.0000\n",
      "epoch [22/100], loss:0.0000\n",
      "epoch [23/100], loss:0.0000\n",
      "epoch [24/100], loss:0.0000\n",
      "epoch [25/100], loss:0.0000\n",
      "epoch [26/100], loss:0.0000\n",
      "epoch [27/100], loss:0.0000\n",
      "epoch [28/100], loss:0.0000\n",
      "epoch [29/100], loss:0.0000\n",
      "epoch [30/100], loss:0.0000\n",
      "epoch [31/100], loss:0.0000\n",
      "epoch [32/100], loss:0.0000\n",
      "epoch [33/100], loss:0.0000\n",
      "epoch [34/100], loss:0.0000\n",
      "epoch [35/100], loss:0.0000\n",
      "epoch [36/100], loss:0.0000\n",
      "epoch [37/100], loss:0.0000\n",
      "epoch [38/100], loss:0.0000\n",
      "epoch [39/100], loss:0.0000\n",
      "epoch [40/100], loss:0.0000\n",
      "epoch [41/100], loss:0.0000\n",
      "epoch [42/100], loss:0.0000\n",
      "epoch [43/100], loss:0.0000\n",
      "epoch [44/100], loss:0.0000\n",
      "epoch [45/100], loss:0.0000\n",
      "epoch [46/100], loss:0.0000\n",
      "epoch [47/100], loss:0.0000\n",
      "epoch [48/100], loss:0.0000\n",
      "epoch [49/100], loss:0.0000\n",
      "epoch [50/100], loss:0.0000\n",
      "epoch [51/100], loss:0.0000\n",
      "epoch [52/100], loss:0.0000\n",
      "epoch [53/100], loss:0.0000\n",
      "epoch [54/100], loss:0.0000\n",
      "epoch [55/100], loss:0.0000\n",
      "epoch [56/100], loss:0.0000\n",
      "epoch [57/100], loss:0.0000\n",
      "epoch [58/100], loss:0.0000\n",
      "epoch [59/100], loss:0.0000\n",
      "epoch [60/100], loss:0.0000\n",
      "epoch [61/100], loss:0.0000\n",
      "epoch [62/100], loss:0.0000\n",
      "epoch [63/100], loss:0.0000\n",
      "epoch [64/100], loss:0.0000\n",
      "epoch [65/100], loss:0.0000\n",
      "epoch [66/100], loss:0.0000\n",
      "epoch [67/100], loss:0.0000\n",
      "epoch [68/100], loss:0.0000\n",
      "epoch [69/100], loss:0.0000\n",
      "epoch [70/100], loss:0.0000\n",
      "epoch [71/100], loss:0.0000\n",
      "epoch [72/100], loss:0.0000\n",
      "epoch [73/100], loss:0.0000\n",
      "epoch [74/100], loss:0.0000\n",
      "epoch [75/100], loss:0.0000\n",
      "epoch [76/100], loss:0.0000\n",
      "epoch [77/100], loss:0.0000\n",
      "epoch [78/100], loss:0.0000\n",
      "epoch [79/100], loss:0.0000\n",
      "epoch [80/100], loss:0.0000\n",
      "epoch [81/100], loss:0.0000\n",
      "epoch [82/100], loss:0.0000\n",
      "epoch [83/100], loss:0.0000\n",
      "epoch [84/100], loss:0.0000\n",
      "epoch [85/100], loss:0.0000\n",
      "epoch [86/100], loss:0.0000\n",
      "epoch [87/100], loss:0.0000\n",
      "epoch [88/100], loss:0.0000\n",
      "epoch [89/100], loss:0.0000\n",
      "epoch [90/100], loss:0.0000\n",
      "epoch [91/100], loss:0.0000\n",
      "epoch [92/100], loss:0.0000\n",
      "epoch [93/100], loss:0.0000\n",
      "epoch [94/100], loss:0.0000\n",
      "epoch [95/100], loss:0.0000\n",
      "epoch [96/100], loss:0.0000\n",
      "epoch [97/100], loss:0.0000\n",
      "epoch [98/100], loss:0.0000\n",
      "epoch [99/100], loss:0.0000\n",
      "epoch [100/100], loss:0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import torch.utils.data as Data\n",
    "if not os.path.exists('./dc_img'):\n",
    "    os.mkdir('./dc_img')\n",
    "\n",
    "\n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 1000\n",
    "learning_rate = 1e-3\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "data1 = cv2.imread('pos1_28x28.png')\n",
    "data2= cv2.imread('pos2_28x28.png')\n",
    "\n",
    "result = np.repeat(data1[np.newaxis,...], 60000, axis=0)\n",
    "print(result.shape)\n",
    "y0 = result.astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result1 = np.repeat(data2[np.newaxis,...], 60000, axis=0)\n",
    "y1 = result1.astype('float32')\n",
    "\n",
    "\n",
    "y0 = np.transpose(y0, (0, 3, 2, 1))# This to make channels first for CNN\n",
    "y1 = np.transpose(y1, (0, 3, 2, 1)) \n",
    "\n",
    "\n",
    "print(y0.shape)\n",
    "\n",
    "x = torch.from_numpy(y0)\n",
    "y = torch.from_numpy(y1)\n",
    "\n",
    "\n",
    "\n",
    "torch_dataset = Data.TensorDataset(x,y)\n",
    "\n",
    "\n",
    "loader = Data.DataLoader(\n",
    "\n",
    "    dataset=torch_dataset,\n",
    "\n",
    "    batch_size=250,\n",
    "\n",
    "    shuffle=True,\n",
    "\n",
    "    num_workers=0,\n",
    "\n",
    ")\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)  \n",
    "        # conv layer (depth from 16 --> 4), 3x3 kernels\n",
    "        self.conv2 = nn.Conv2d(16, 4, 3, padding=1)\n",
    "        # pooling layer to reduce x-y dims by two; kernel and stride of 2\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## encode ##\n",
    "        # add hidden layers with relu activation function\n",
    "        # and maxpooling after\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #x = self.pool(x)\n",
    "        # add second hidden layer\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #x = self.pool(x)  # compressed representation\n",
    "        \n",
    "\n",
    "        return x\n",
    "\n",
    "class auto_decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(auto_decoder,self).__init__()\n",
    "        ## decoder layers ##\n",
    "        ## a kernel of 2 and a stride of 2 will increase the spatial dims by 2\n",
    "        self.t_conv1 = nn.ConvTranspose2d(4, 16, 3,padding=1)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(16, 3, 3,padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ## decode ##\n",
    "        # add transpose conv layers, with relu activation function\n",
    "        x = F.relu(self.t_conv1(x))\n",
    "        # output layer (with sigmoid for scaling from 0 to 1)\n",
    "        x = F.sigmoid(self.t_conv2(x))\n",
    "                \n",
    "        return x\n",
    "    \n",
    "\n",
    "model = autoencoder()\n",
    "\n",
    "\n",
    "def h_score(fx, gy):\n",
    " \n",
    "    fx = fx - fx.mean(0)\n",
    "\n",
    "    gy = gy - gy.mean(0)\n",
    "\n",
    "    Nsamples = fx.size(0)\n",
    "\n",
    "    covf = torch.matmul((fx.permute(0, 1,3,2)), fx) / Nsamples\n",
    "\n",
    "    covg = torch.matmul((gy.permute(0, 1,3,2)), (gy)) / Nsamples\n",
    "\n",
    "    h = -2 * torch.mean((fx * gy).sum(1)) + (covf * covg).sum()\n",
    "\n",
    "    return h\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                             weight_decay=1e-5)\n",
    "\n",
    "model_1 = auto_decoder()\n",
    "optimizer_1 = torch.optim.Adam(model_1.parameters(), lr=learning_rate,\n",
    "                             weight_decay=1e-5)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for x,y in loader:\n",
    "\n",
    "        # ===================forward=====================\n",
    "        #loss = criterion(output1, img)\n",
    "        loss = h_score(model(x),model(y))\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        #optimizer_1.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #optimizer_1.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), './conv_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 3, 3]) torch.Size([4, 16, 3, 3]) torch.Size([4, 16, 3, 3]) torch.Size([16, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "z1 = model.conv1.weight\n",
    "z2 = model.conv2.weight\n",
    "z1 = torch.nn.Parameter(z1)\n",
    "z2 = torch.nn.Parameter(z2)\n",
    "\n",
    "\n",
    "\n",
    "model_1.t_conv1.weight = torch.nn.Parameter(z2.permute(0,1,3,2))\n",
    "model_1.t_conv2.weight = torch.nn.Parameter(z1.permute(0,1,3,2))\n",
    "z3 = model_1.t_conv1.weight\n",
    "z4 = model_1.t_conv2.weight\n",
    "\n",
    "print(np.shape(z1),np.shape(z2),np.shape(z3),np.shape(z4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# obtain one batch of test images\n",
    "dataiter = iter(dataloader)\n",
    "images, labels = dataiter.next()\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(data1)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    k = model(x[i].reshape(1,3,28,28))\n",
    "    z = (model_1(k)).reshape(28, 28,3)\n",
    "    plt.imshow(z.detach().numpy())\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "print(np.shape(k))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
