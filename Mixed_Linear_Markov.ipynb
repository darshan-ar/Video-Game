{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n",
      "(20000, 28, 28)\n",
      "epoch [1/200], loss:0.0001\n",
      "torch.Size([784])\n",
      "x:  tensor([0.2349], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.2570], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.2322]], grad_fn=<SigmoidBackward>)\n",
      "epoch [2/200], loss:-0.0013\n",
      "torch.Size([784])\n",
      "x:  tensor([0.5683], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.2710], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.5281]], grad_fn=<SigmoidBackward>)\n",
      "epoch [3/200], loss:-0.0033\n",
      "torch.Size([784])\n",
      "x:  tensor([0.5166], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9274], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.8196]], grad_fn=<SigmoidBackward>)\n",
      "epoch [4/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0363], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0045], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0225]], grad_fn=<SigmoidBackward>)\n",
      "epoch [5/200], loss:-0.0090\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9575], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.6775], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.7655]], grad_fn=<SigmoidBackward>)\n",
      "epoch [6/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9979], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9978], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9982]], grad_fn=<SigmoidBackward>)\n",
      "epoch [7/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9985], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9978], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9982]], grad_fn=<SigmoidBackward>)\n",
      "epoch [8/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9981], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9974], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9982]], grad_fn=<SigmoidBackward>)\n",
      "epoch [9/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9972], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9988], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9982]], grad_fn=<SigmoidBackward>)\n",
      "epoch [10/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9983], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9983], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9982]], grad_fn=<SigmoidBackward>)\n",
      "epoch [11/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9971], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9984], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9981]], grad_fn=<SigmoidBackward>)\n",
      "epoch [12/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9985], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9962], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9981]], grad_fn=<SigmoidBackward>)\n",
      "epoch [13/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9955], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9967], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9981]], grad_fn=<SigmoidBackward>)\n",
      "epoch [14/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9982], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9970], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9981]], grad_fn=<SigmoidBackward>)\n",
      "epoch [15/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9983], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9983], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9980]], grad_fn=<SigmoidBackward>)\n",
      "epoch [16/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9970], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9968], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9980]], grad_fn=<SigmoidBackward>)\n",
      "epoch [17/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9969], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9976], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9980]], grad_fn=<SigmoidBackward>)\n",
      "epoch [18/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9978], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9964], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9979]], grad_fn=<SigmoidBackward>)\n",
      "epoch [19/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9974], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9979], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9979]], grad_fn=<SigmoidBackward>)\n",
      "epoch [20/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9980], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9973], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9978]], grad_fn=<SigmoidBackward>)\n",
      "epoch [21/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9967], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9972], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9977]], grad_fn=<SigmoidBackward>)\n",
      "epoch [22/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9968], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9965], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9977]], grad_fn=<SigmoidBackward>)\n",
      "epoch [23/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9983], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9982], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9976]], grad_fn=<SigmoidBackward>)\n",
      "epoch [24/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9957], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9978], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9975]], grad_fn=<SigmoidBackward>)\n",
      "epoch [25/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9979], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9970], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9975]], grad_fn=<SigmoidBackward>)\n",
      "epoch [26/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9966], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9978], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9974]], grad_fn=<SigmoidBackward>)\n",
      "epoch [27/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9963], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9942], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9973]], grad_fn=<SigmoidBackward>)\n",
      "epoch [28/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9954], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9964], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9973]], grad_fn=<SigmoidBackward>)\n",
      "epoch [29/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9969], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9973], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9972]], grad_fn=<SigmoidBackward>)\n",
      "epoch [30/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9945], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9969], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9971]], grad_fn=<SigmoidBackward>)\n",
      "epoch [31/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9970], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9968], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9970]], grad_fn=<SigmoidBackward>)\n",
      "epoch [32/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9927], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9969], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9969]], grad_fn=<SigmoidBackward>)\n",
      "epoch [33/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9973], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9962], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9967]], grad_fn=<SigmoidBackward>)\n",
      "epoch [34/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9939], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9960], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9966]], grad_fn=<SigmoidBackward>)\n",
      "epoch [35/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9945], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9974], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9965]], grad_fn=<SigmoidBackward>)\n",
      "epoch [36/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9942], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9955], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9963]], grad_fn=<SigmoidBackward>)\n",
      "epoch [37/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9963], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9947], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9961]], grad_fn=<SigmoidBackward>)\n",
      "epoch [38/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9964], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9942], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9959]], grad_fn=<SigmoidBackward>)\n",
      "epoch [39/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9961], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9940], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9957]], grad_fn=<SigmoidBackward>)\n",
      "epoch [40/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9954], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9922], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9955]], grad_fn=<SigmoidBackward>)\n",
      "epoch [41/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9919], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9967], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9952]], grad_fn=<SigmoidBackward>)\n",
      "epoch [42/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9912], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9928], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9950]], grad_fn=<SigmoidBackward>)\n",
      "epoch [43/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9938], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9949], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9946]], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [44/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9950], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9942], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9943]], grad_fn=<SigmoidBackward>)\n",
      "epoch [45/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9879], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9911], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9939]], grad_fn=<SigmoidBackward>)\n",
      "epoch [46/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9933], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9934], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9934]], grad_fn=<SigmoidBackward>)\n",
      "epoch [47/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9925], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9946], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9928]], grad_fn=<SigmoidBackward>)\n",
      "epoch [48/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9922], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9893], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9921]], grad_fn=<SigmoidBackward>)\n",
      "epoch [49/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9888], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9918], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9912]], grad_fn=<SigmoidBackward>)\n",
      "epoch [50/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9863], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9851], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9898]], grad_fn=<SigmoidBackward>)\n",
      "epoch [51/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9629], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9852], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9871]], grad_fn=<SigmoidBackward>)\n",
      "epoch [52/200], loss:-0.0003\n",
      "torch.Size([784])\n",
      "x:  tensor([0.8737], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.8267], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.8594]], grad_fn=<SigmoidBackward>)\n",
      "epoch [53/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9992], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9989], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9990]], grad_fn=<SigmoidBackward>)\n",
      "epoch [54/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9995], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9990], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9989]], grad_fn=<SigmoidBackward>)\n",
      "epoch [55/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9990], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9993], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9989]], grad_fn=<SigmoidBackward>)\n",
      "epoch [56/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9994], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9991], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9989]], grad_fn=<SigmoidBackward>)\n",
      "epoch [57/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9985], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9988], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9988]], grad_fn=<SigmoidBackward>)\n",
      "epoch [58/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9993], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9990], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9988]], grad_fn=<SigmoidBackward>)\n",
      "epoch [59/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9994], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9992], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9987]], grad_fn=<SigmoidBackward>)\n",
      "epoch [60/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9994], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9992], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9986]], grad_fn=<SigmoidBackward>)\n",
      "epoch [61/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9988], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9990], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9986]], grad_fn=<SigmoidBackward>)\n",
      "epoch [62/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9992], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9984], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9985]], grad_fn=<SigmoidBackward>)\n",
      "epoch [63/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9990], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9986], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9984]], grad_fn=<SigmoidBackward>)\n",
      "epoch [64/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9993], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9987], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9983]], grad_fn=<SigmoidBackward>)\n",
      "epoch [65/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9988], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9967], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9982]], grad_fn=<SigmoidBackward>)\n",
      "epoch [66/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9985], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9986], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9981]], grad_fn=<SigmoidBackward>)\n",
      "epoch [67/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9991], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9982], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9980]], grad_fn=<SigmoidBackward>)\n",
      "epoch [68/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9986], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9976], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9978]], grad_fn=<SigmoidBackward>)\n",
      "epoch [69/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9988], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9981], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9977]], grad_fn=<SigmoidBackward>)\n",
      "epoch [70/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9989], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9978], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9975]], grad_fn=<SigmoidBackward>)\n",
      "epoch [71/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9982], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9959], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9973]], grad_fn=<SigmoidBackward>)\n",
      "epoch [72/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9978], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9974], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9971]], grad_fn=<SigmoidBackward>)\n",
      "epoch [73/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9981], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9977], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9969]], grad_fn=<SigmoidBackward>)\n",
      "epoch [74/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9977], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9967], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9966]], grad_fn=<SigmoidBackward>)\n",
      "epoch [75/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9967], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9950], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9963]], grad_fn=<SigmoidBackward>)\n",
      "epoch [76/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9976], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9975], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9960]], grad_fn=<SigmoidBackward>)\n",
      "epoch [77/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9971], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9971], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9956]], grad_fn=<SigmoidBackward>)\n",
      "epoch [78/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9957], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9951], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9951]], grad_fn=<SigmoidBackward>)\n",
      "epoch [79/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9954], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9950], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9945]], grad_fn=<SigmoidBackward>)\n",
      "epoch [80/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9941], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9944], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9938]], grad_fn=<SigmoidBackward>)\n",
      "epoch [81/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9946], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9951], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9930]], grad_fn=<SigmoidBackward>)\n",
      "epoch [82/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9965], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9937], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9921]], grad_fn=<SigmoidBackward>)\n",
      "epoch [83/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9940], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9942], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9908]], grad_fn=<SigmoidBackward>)\n",
      "epoch [84/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9900], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9865], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9890]], grad_fn=<SigmoidBackward>)\n",
      "epoch [85/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9912], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9896], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9864]], grad_fn=<SigmoidBackward>)\n",
      "epoch [86/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9877], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9827], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9817]], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [87/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.9739], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.9758], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.9682]], grad_fn=<SigmoidBackward>)\n",
      "epoch [88/200], loss:-0.0005\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0041], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0187], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0231]], grad_fn=<SigmoidBackward>)\n",
      "epoch [89/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([8.2983e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([8.2150e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.3863e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [90/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([3.4478e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([7.7184e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.8482e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [91/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([2.2060e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.7167e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.4181e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [92/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([2.2415e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([8.0907e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.1170e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [93/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([2.1726e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.8217e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.9767e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [94/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([9.6647e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.3026e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[6.0399e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [95/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([5.5604e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([6.9121e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[7.3647e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [96/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.7536e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.1087e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[9.0092e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [97/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([2.5676e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.7761e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.1056e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [98/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([9.2542e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([6.3000e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.3609e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [99/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.1223e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.3054e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.6804e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [100/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([3.3470e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.4776e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.0810e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [101/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([5.7828e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.7431e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.5842e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [102/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.8773e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.4507e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.2366e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [103/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([3.4440e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([4.7998e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.0934e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [104/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([2.5318e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.8885e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[5.1905e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [105/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.1364e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([4.1298e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[6.5922e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [106/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([9.7604e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[8.3848e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [107/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([6.8309e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "epoch [108/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([6.7228e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0003], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "epoch [109/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0003], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "epoch [110/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([8.5078e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([6.7519e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "epoch [111/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0003], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0003]], grad_fn=<SigmoidBackward>)\n",
      "epoch [112/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0004]], grad_fn=<SigmoidBackward>)\n",
      "epoch [113/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0009], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0007], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0005]], grad_fn=<SigmoidBackward>)\n",
      "epoch [114/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0003], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0008], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0006]], grad_fn=<SigmoidBackward>)\n",
      "epoch [115/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0009], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0007], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0008]], grad_fn=<SigmoidBackward>)\n",
      "epoch [116/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0014], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0011], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0011]], grad_fn=<SigmoidBackward>)\n",
      "epoch [117/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0013], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0055], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0015]], grad_fn=<SigmoidBackward>)\n",
      "epoch [118/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0022], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0010], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0022]], grad_fn=<SigmoidBackward>)\n",
      "epoch [119/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0026], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0034], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0039]], grad_fn=<SigmoidBackward>)\n",
      "epoch [120/200], loss:-0.0101\n",
      "torch.Size([784])\n",
      "x:  tensor([0.7071], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.1251], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.1741]], grad_fn=<SigmoidBackward>)\n",
      "epoch [121/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([9.7138e-08], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.3943e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.4306e-07]], grad_fn=<SigmoidBackward>)\n",
      "epoch [122/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([2.3846e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.9428e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.4920e-07]], grad_fn=<SigmoidBackward>)\n",
      "epoch [123/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([9.3010e-08], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([8.1684e-08], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.8056e-07]], grad_fn=<SigmoidBackward>)\n",
      "epoch [124/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.3835e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.6026e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.1589e-07]], grad_fn=<SigmoidBackward>)\n",
      "epoch [125/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.4782e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.6383e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.5575e-07]], grad_fn=<SigmoidBackward>)\n",
      "epoch [126/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([7.4276e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.2130e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[5.0088e-07]], grad_fn=<SigmoidBackward>)\n",
      "epoch [127/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.3767e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.1770e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[5.5211e-07]], grad_fn=<SigmoidBackward>)\n",
      "epoch [128/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.8145e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([4.2880e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[6.1035e-07]], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [129/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.8818e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.0153e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[6.7673e-07]], grad_fn=<SigmoidBackward>)\n",
      "epoch [130/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([3.7120e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([6.1008e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[7.5258e-07]], grad_fn=<SigmoidBackward>)\n",
      "epoch [131/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([5.5024e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([6.4771e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[8.3943e-07]], grad_fn=<SigmoidBackward>)\n",
      "epoch [132/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.4295e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([5.7765e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[9.3917e-07]], grad_fn=<SigmoidBackward>)\n",
      "epoch [133/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([6.0712e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([6.1263e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.0540e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [134/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([6.1673e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.3755e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.1867e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [135/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([3.5025e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([5.5014e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.3416e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [136/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.2825e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([5.8922e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5271e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [137/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([2.4006e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([6.2380e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.7438e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [138/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.8332e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.2495e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.9977e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [139/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([9.6600e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([9.8173e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.2959e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [140/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([6.9267e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([8.5533e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.6471e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [141/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.1917e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.3338e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.0621e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [142/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([4.1646e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([5.4229e-07], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.5538e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [143/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.0673e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.7885e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.1381e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [144/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([3.7814e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.2247e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.8345e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [145/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.7484e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.1149e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[5.6602e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [146/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.0245e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([4.9499e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[6.6468e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [147/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.0797e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.3025e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[7.8317e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [148/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([2.5101e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([7.8114e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[9.2590e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [149/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([7.4197e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([7.7181e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.0983e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [150/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([8.1124e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([7.7861e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.3070e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [151/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([7.0024e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.4054e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5605e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [152/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([9.6925e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([8.9568e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.8690e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [153/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([9.5770e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.5458e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.2456e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [154/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.3762e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([4.8056e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.7061e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [155/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([2.0322e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.1559e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.2734e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [156/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([3.5038e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.8900e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.9822e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [157/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([1.5038e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([9.2337e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.8594e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [158/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([5.9735e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([8.4045e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[5.9448e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [159/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([2.9661e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([4.0167e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[7.2902e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [160/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([5.4888e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([7.2491e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[8.9605e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [161/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([3.5230e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([4.6996e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "epoch [162/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([6.8180e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "epoch [163/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([7.5676e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.1877e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "epoch [164/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0003], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "epoch [165/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0003], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0003]], grad_fn=<SigmoidBackward>)\n",
      "epoch [166/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0004], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0003]], grad_fn=<SigmoidBackward>)\n",
      "epoch [167/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0004], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0007], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0004]], grad_fn=<SigmoidBackward>)\n",
      "epoch [168/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0003], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0004], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0005]], grad_fn=<SigmoidBackward>)\n",
      "epoch [169/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0003], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0006], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0006]], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [170/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0009], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0005], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0008]], grad_fn=<SigmoidBackward>)\n",
      "epoch [171/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0006], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0009], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0010]], grad_fn=<SigmoidBackward>)\n",
      "epoch [172/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0006], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0007], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0013]], grad_fn=<SigmoidBackward>)\n",
      "epoch [173/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0011], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0011], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0016]], grad_fn=<SigmoidBackward>)\n",
      "epoch [174/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0016], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0020], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0020]], grad_fn=<SigmoidBackward>)\n",
      "epoch [175/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0014], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0018], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0026]], grad_fn=<SigmoidBackward>)\n",
      "epoch [176/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0014], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0019], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0034]], grad_fn=<SigmoidBackward>)\n",
      "epoch [177/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0022], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0039], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0046]], grad_fn=<SigmoidBackward>)\n",
      "epoch [178/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0049], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0042], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0064]], grad_fn=<SigmoidBackward>)\n",
      "epoch [179/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0099], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0094], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0098]], grad_fn=<SigmoidBackward>)\n",
      "epoch [180/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0202], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0188], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0184]], grad_fn=<SigmoidBackward>)\n",
      "epoch [181/200], loss:-0.0054\n",
      "torch.Size([784])\n",
      "x:  tensor([0.1265], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.4776], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.3631]], grad_fn=<SigmoidBackward>)\n",
      "epoch [182/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([5.2943e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.4106e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.4552e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [183/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([9.0921e-07], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.4955e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.8955e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [184/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([3.7105e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.9974e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.4720e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [185/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([4.2661e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([4.3534e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.2251e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [186/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([2.4927e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.0741e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.2020e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [187/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([6.6435e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.2748e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[5.4728e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [188/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([4.3028e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([5.4222e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[7.1298e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [189/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([6.3732e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.2709e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[9.2946e-06]], grad_fn=<SigmoidBackward>)\n",
      "epoch [190/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([2.9916e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([5.1138e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.2133e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [191/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([6.3290e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([1.1319e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[1.5860e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [192/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([4.0808e-06], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([8.5532e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.0768e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [193/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([4.2072e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([8.0403e-06], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[2.7241e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [194/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([2.9534e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.0955e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[3.5791e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [195/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([4.7805e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.7651e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[4.7097e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [196/200], loss:0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([4.5060e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([5.2136e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[6.2061e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [197/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([3.2782e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([2.2431e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[8.1880e-05]], grad_fn=<SigmoidBackward>)\n",
      "epoch [198/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([6.7019e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([3.2117e-05], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "epoch [199/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "epoch [200/200], loss:-0.0000\n",
      "torch.Size([784])\n",
      "x:  tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.utils.data as Data\n",
    "from PIL import  Image,ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "Batch_Size = 250\n",
    "num_epochs = 200\n",
    "learning_rate = 1e-4\n",
    "samples = 20000\n",
    "\n",
    "data1 = []\n",
    "data2= []\n",
    "\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% --  Generate dataset\n",
    "\n",
    "\n",
    "for i in range(samples):\n",
    "    img = Image.new('RGB', (28, 28), color = 'white')\n",
    "    row,col,ch= np.shape(img)\n",
    "    mean = 0\n",
    "    var = 1\n",
    "    sigma = var**0.5\n",
    "    gauss_pos1 = np.random.normal(mean,sigma,(row,col,ch))\n",
    "    noisy_pos1 = img + gauss_pos1\n",
    "    im2_pos1 = Image.fromarray(noisy_pos1,'RGB')\n",
    "    draw = ImageDraw.Draw(im2_pos1)\n",
    "    draw.rectangle([9,12,12,15],fill='red',outline='red')\n",
    "    data1.append(np.asarray(im2_pos1))\n",
    "\n",
    "\n",
    "\n",
    "for i in range(samples):\n",
    "    img = Image.new('RGB', (28, 28), color = 'white')\n",
    "    row,col,ch= np.shape(img)\n",
    "    mean = 0\n",
    "    var = 1\n",
    "    sigma = var**0.5\n",
    "    gauss_pos2 = np.random.normal(mean,sigma,(row,col,ch))\n",
    "    noisy_pos2 = img + gauss_pos2\n",
    "    im2_pos2 = Image.fromarray(noisy_pos2,'RGB')\n",
    "    r = np.random.choice(np.arange(1, 3), p=[0.5,0.5])\n",
    "    draw = ImageDraw.Draw(im2_pos2)\n",
    "    draw.rectangle([21, 12, 24, 15], fill='red', outline='red')\n",
    "    data2.append(np.asarray(im2_pos2))\n",
    "\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%% Noisy data\n",
    "img = Image.new('RGB', (28, 28), color = 'white')\n",
    "row,col,ch= np.shape(img)\n",
    "mean = 0\n",
    "var = 1\n",
    "sigma = var**0.5\n",
    "gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "noisy = img + gauss\n",
    "im2 = Image.fromarray(noisy,'RGB')\n",
    "b = np.asarray(im2)\n",
    "b = np.array(b, dtype=np.float32)\n",
    "b=b[:,:,0]\n",
    "b = torch.from_numpy(b)\n",
    "print(np.shape(b))\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%       \n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% - Data Preparation\n",
    "\n",
    "y0 = np.array(data1, dtype=np.float32)\n",
    "y1 = np.array(data2, dtype=np.float32)\n",
    "y0 = y0[:,:,:,0]\n",
    "y1 = y1[:,:,:,0]\n",
    "\n",
    "print(y0.shape)\n",
    "\n",
    "x = torch.from_numpy(y0)\n",
    "y = torch.from_numpy(y1)\n",
    "\n",
    "\n",
    "torch_dataset = Data.TensorDataset(x,y)\n",
    "\n",
    "\n",
    "loader = Data.DataLoader(\n",
    "\n",
    "    dataset=torch_dataset,\n",
    "\n",
    "    batch_size=Batch_Size,\n",
    "\n",
    "    shuffle=True,\n",
    "\n",
    "    num_workers=0,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% - Defining NN\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder_hidden_layer = nn.Linear(\n",
    "            in_features=kwargs[\"input_shape\"], out_features=128\n",
    "        )\n",
    "        self.encoder_output_layer = nn.Linear(\n",
    "            in_features=128, out_features=64\n",
    "        )\n",
    "        self.encoder_output_layer_1 = nn.Linear(\n",
    "            in_features=64, out_features=32\n",
    "        )\n",
    "        self.encoder_output_layer_2 = nn.Linear(\n",
    "            in_features=32, out_features=16\n",
    "        )\n",
    "        self.encoder_output_layer_3 = nn.Linear(\n",
    "            in_features=16, out_features=8\n",
    "        )\n",
    "        self.encoder_output_layer_4 = nn.Linear(\n",
    "            in_features=8, out_features=1\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, features):\n",
    "        activation = self.encoder_hidden_layer(features)\n",
    "        activation = torch.relu(activation)\n",
    "        code = self.encoder_output_layer(activation)\n",
    "        code = torch.relu(code)\n",
    "        code = self.encoder_output_layer_1(code)\n",
    "        code = torch.relu(code)\n",
    "        code = self.encoder_output_layer_2(code)\n",
    "        code = torch.relu(code)\n",
    "        code = self.encoder_output_layer_3(code)\n",
    "        code = torch.relu(code)\n",
    "        code = self.encoder_output_layer_4(code)\n",
    "        code = torch.sigmoid(code)\n",
    "        return code\n",
    "\n",
    "#  use gpu if available\n",
    "\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "model = AE(input_shape=784)\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% - Loss Function\n",
    "\n",
    "def h_score(fx, gy):\n",
    " \n",
    "    fx = fx - fx.mean(0)\n",
    "\n",
    "    gy = gy - gy.mean(0)\n",
    "\n",
    "    Nsamples = fx.size(0)\n",
    "\n",
    "    covf = torch.matmul((fx.t()), fx) / Nsamples\n",
    "\n",
    "    covg = torch.matmul((gy.t()), (gy)) / Nsamples\n",
    "\n",
    "    h = -2 * torch.mean((fx * gy).sum(1)) + (covf * covg).sum()\n",
    "\n",
    "    return h\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for x,y in loader:\n",
    "        optimizer.zero_grad()\n",
    "        # ===================forward=====================\n",
    "        #loss = criterion(output1, img)\n",
    "        x = x.view(-1, 784)\n",
    "        y = y.view(-1, 784)\n",
    "        loss = h_score(model(x),model(y))\n",
    "        # ===================backward====================\n",
    "\n",
    "        #optimizer_1.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #optimizer_1.step()\n",
    "    # ===================log========================\n",
    "    b = b.view(-1,784)\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "    print(np.shape(x[0]))\n",
    "    print(\"x: \", model(x[0]))\n",
    "    print(\"y:\", model(y[0]))\n",
    "    print(\"b:\", model(b))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[9.2063e-05]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([8.8987e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([5.6431e-05], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([5.7819e-05], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([8.0801e-05], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([3.5437e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([6.6648e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([7.5665e-05], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([9.3397e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([9.5179e-05], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[9.3757e-05]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[8.9585e-05]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[9.7860e-05]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[8.8462e-05]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([8.0607e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([9.9725e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([8.8895e-05], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[8.3272e-05]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([6.9779e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0002], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([9.0415e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[0.0001]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([9.3979e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([7.5346e-05], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n",
      "b: tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "z:  tensor([[0.0002]], grad_fn=<SigmoidBackward>)\n",
      "x:  tensor([6.8715e-05], grad_fn=<SigmoidBackward>)\n",
      "y: tensor([0.0001], grad_fn=<SigmoidBackward>)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    img = Image.new('RGB', (28, 28), color = 'white')\n",
    "    row,col,ch= np.shape(img)\n",
    "    mean = 0\n",
    "    var = 1\n",
    "    sigma = var**0.5\n",
    "    gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "    noisy = img + gauss\n",
    "    im2_n = Image.fromarray(noisy,'RGB')\n",
    "    b = np.asarray(im2_n)\n",
    "    b = np.array(b, dtype=np.float32)\n",
    "    b = torch.from_numpy(b)\n",
    "    im2_test = Image.fromarray(noisy,'RGB')\n",
    "    draw1 = ImageDraw.Draw(im2_test)\n",
    "    draw1.rectangle([5, 9, 8, 12], fill='red', outline='red')\n",
    "    z = np.asarray(im2_test)\n",
    "    z = np.array(z, dtype=np.float32)\n",
    "    z = torch.from_numpy(z)\n",
    "    b=b[:,:,0]\n",
    "    z=z[:,:,0]\n",
    "    print(\"b:\", model(b.view(-1,784)))\n",
    "    print(\"z: \", model(z.view(-1,784)))\n",
    "    print(\"x: \", model(x[i]))\n",
    "    print(\"y:\", model(y[i]))\n",
    "    print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "    print(\"  \")\n",
    "    p = Image.fromarray(data1[i])\n",
    "    #p.show()\n",
    "    q = Image.fromarray(data2[i])\n",
    "    #q.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
