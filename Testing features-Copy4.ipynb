{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3, 100, 100)\n",
      "epoch [1/200], loss:-0.0257\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [2/200], loss:-0.0915\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [3/200], loss:-0.1676\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [4/200], loss:-0.1811\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [5/200], loss:-0.2257\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [6/200], loss:-0.2550\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [7/200], loss:-0.3352\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [8/200], loss:-0.3280\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [9/200], loss:-0.5701\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [10/200], loss:-0.6247\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [11/200], loss:-0.8798\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [12/200], loss:-0.9232\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [13/200], loss:-1.0664\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [14/200], loss:-1.1686\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [15/200], loss:-1.4242\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [16/200], loss:-1.2237\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [17/200], loss:-1.6404\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [18/200], loss:-1.3954\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [19/200], loss:-1.3857\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [20/200], loss:-1.3983\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [21/200], loss:-1.5925\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [22/200], loss:-1.6403\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [23/200], loss:-1.4881\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [24/200], loss:-1.7085\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [25/200], loss:-1.6456\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [26/200], loss:-1.6210\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [27/200], loss:-1.5379\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [28/200], loss:-1.7893\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [29/200], loss:-1.6222\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [30/200], loss:-1.5996\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [31/200], loss:-1.4661\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [32/200], loss:-1.6308\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [33/200], loss:-1.7376\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [34/200], loss:-1.5948\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [35/200], loss:-1.7526\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [36/200], loss:-1.6904\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [37/200], loss:-1.6957\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [38/200], loss:-1.5606\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [39/200], loss:-1.9004\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [40/200], loss:-1.5083\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [41/200], loss:-1.7100\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [42/200], loss:-1.6558\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [43/200], loss:-1.5420\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [44/200], loss:-1.6289\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [45/200], loss:-1.7598\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [46/200], loss:-1.7006\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [47/200], loss:-1.7645\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [48/200], loss:-1.8134\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [49/200], loss:-1.5103\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [50/200], loss:-1.8364\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [51/200], loss:-1.7660\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [52/200], loss:-1.5880\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [53/200], loss:-1.9530\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [54/200], loss:-1.6563\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [55/200], loss:-1.7612\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [56/200], loss:-1.6280\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [57/200], loss:-1.6894\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [58/200], loss:-1.6503\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [59/200], loss:-1.8806\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [60/200], loss:-1.6301\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [61/200], loss:-1.6668\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [62/200], loss:-1.7592\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [63/200], loss:-1.6900\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [64/200], loss:-1.8345\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [65/200], loss:-1.7397\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [66/200], loss:-1.7743\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [67/200], loss:-1.6283\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [68/200], loss:-1.8500\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [69/200], loss:-1.7414\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [70/200], loss:-1.7276\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [71/200], loss:-1.7766\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [72/200], loss:-1.6630\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [73/200], loss:-1.7787\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [74/200], loss:-1.8267\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [75/200], loss:-1.9209\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [76/200], loss:-1.5263\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [77/200], loss:-1.4952\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [78/200], loss:-1.6169\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [79/200], loss:-1.7221\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [80/200], loss:-1.7285\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [81/200], loss:-1.8047\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [82/200], loss:-1.6791\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [83/200], loss:-1.5536\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [84/200], loss:-1.8157\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [85/200], loss:-1.5841\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [86/200], loss:-1.7381\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [87/200], loss:-1.8532\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [88/200], loss:-1.8212\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [89/200], loss:-1.7304\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [90/200], loss:-1.6714\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [91/200], loss:-1.6041\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [92/200], loss:-1.7289\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [93/200], loss:-1.9233\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [94/200], loss:-1.6059\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [95/200], loss:-1.5869\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [96/200], loss:-1.7922\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [97/200], loss:-1.7795\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [98/200], loss:-1.5850\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [99/200], loss:-1.6817\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [100/200], loss:-1.5434\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [101/200], loss:-1.7160\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [102/200], loss:-1.8010\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [103/200], loss:-1.6993\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [104/200], loss:-1.7727\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [105/200], loss:-1.6827\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [106/200], loss:-1.7653\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [107/200], loss:-1.6209\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [108/200], loss:-1.6357\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [109/200], loss:-1.7432\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [110/200], loss:-1.7313\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [111/200], loss:-1.8571\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [112/200], loss:-1.7663\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [113/200], loss:-1.7039\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [114/200], loss:-1.6808\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [115/200], loss:-1.7236\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [116/200], loss:-1.8043\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [117/200], loss:-1.6589\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [118/200], loss:-1.8106\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [119/200], loss:-1.5759\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [120/200], loss:-1.6072\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [121/200], loss:-1.6691\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [122/200], loss:-1.6751\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [123/200], loss:-1.5816\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [124/200], loss:-1.7325\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [125/200], loss:-1.6211\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [126/200], loss:-1.6684\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [127/200], loss:-1.7625\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [128/200], loss:-1.7002\n",
      "shape:  torch.Size([1, 3, 19, 19])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [129/200], loss:-1.7058\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [130/200], loss:-1.5559\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [131/200], loss:-1.6383\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [132/200], loss:-1.5619\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [133/200], loss:-1.6900\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [134/200], loss:-1.6018\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [135/200], loss:-1.6131\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [136/200], loss:-1.6437\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [137/200], loss:-1.7557\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [138/200], loss:-1.9192\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [139/200], loss:-1.6760\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [140/200], loss:-1.8682\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [141/200], loss:-1.5732\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [142/200], loss:-1.7855\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [143/200], loss:-1.8136\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [144/200], loss:-1.7031\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [145/200], loss:-1.6649\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [146/200], loss:-1.5825\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [147/200], loss:-1.8136\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [148/200], loss:-1.8295\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [149/200], loss:-1.7157\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [150/200], loss:-1.8195\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [151/200], loss:-1.6704\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [152/200], loss:-1.5960\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [153/200], loss:-1.7101\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [154/200], loss:-1.7178\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [155/200], loss:-1.6840\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [156/200], loss:-1.6670\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [157/200], loss:-1.7052\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [158/200], loss:-1.7000\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [159/200], loss:-1.8036\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [160/200], loss:-1.7762\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [161/200], loss:-1.6694\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [162/200], loss:-1.7014\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [163/200], loss:-1.6177\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [164/200], loss:-1.7287\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [165/200], loss:-1.6633\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [166/200], loss:-1.6895\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [167/200], loss:-1.6601\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [168/200], loss:-1.6758\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [169/200], loss:-1.8410\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [170/200], loss:-1.9440\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [171/200], loss:-1.7117\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [172/200], loss:-1.6553\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [173/200], loss:-1.7629\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [174/200], loss:-1.5640\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [175/200], loss:-1.7939\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [176/200], loss:-1.6141\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [177/200], loss:-1.6005\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [178/200], loss:-1.7755\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [179/200], loss:-1.8405\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [180/200], loss:-1.6166\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [181/200], loss:-1.6026\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [182/200], loss:-1.6803\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [183/200], loss:-1.5539\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [184/200], loss:-1.8605\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [185/200], loss:-1.7002\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [186/200], loss:-1.7751\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [187/200], loss:-1.7832\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [188/200], loss:-1.5731\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [189/200], loss:-1.6908\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [190/200], loss:-1.8126\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [191/200], loss:-1.6535\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [192/200], loss:-1.6370\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [193/200], loss:-1.6303\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [194/200], loss:-1.7329\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [195/200], loss:-1.7256\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [196/200], loss:-1.7018\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [197/200], loss:-1.6858\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [198/200], loss:-1.7398\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [199/200], loss:-1.5917\n",
      "shape:  torch.Size([1, 3, 19, 19])\n",
      "epoch [200/200], loss:-1.6829\n",
      "shape:  torch.Size([1, 3, 19, 19])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.utils.data as Data\n",
    "from PIL import  Image,ImageDraw\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "Batch_Size = 50\n",
    "num_epochs = 200\n",
    "learning_rate = 1e-5\n",
    "samples = 10000\n",
    "\n",
    "data1 = []\n",
    "data2= []\n",
    "\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% --  Generate dataset\n",
    "uframes = []\n",
    "\n",
    "im1 = Image.open('tree1.png')\n",
    "im1 = im1.resize((8,8))\n",
    "\n",
    "imt = Image.open('tank.png')\n",
    "imt = imt.resize((10,10))\n",
    "\n",
    "\n",
    "im2 = Image.open('tree2.png')\n",
    "im2 = im2.resize((8,8))\n",
    "\n",
    "im3 = Image.open('tree3.png')\n",
    "im3 = im3.resize((8,8))\n",
    "\n",
    "im_drone = Image.open('drone4-1.png')\n",
    "im_drone = im_drone.resize((10,10))\n",
    "\n",
    "imb = Image.open('bullet.png')\n",
    "imb = imb.resize((2,2))\n",
    "\n",
    "for i in range(1):\n",
    "    \n",
    "    #blank\n",
    "    img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "#     img_blank.paste(im1,(5,7),im1)\n",
    "#     img_blank.paste(im1,(45,55),im1)\n",
    "#     img_blank.paste(im1,(25,72),im1)\n",
    "#     img_blank.paste(im2,(50,90),im2)\n",
    "#     img_blank.paste(im2,(60,75),im2)\n",
    "#     img_blank.paste(im2,(30,40),im2)\n",
    "#     img_blank.paste(im3,(10,60),im3)\n",
    "#     img_blank.paste(im3,(44,62),im3)\n",
    "#     img_blank.paste(im3,(30,15),im3)\n",
    "\n",
    "    uframes.append(img_blank)\n",
    "    \n",
    "    #only tank\n",
    "    img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "#     img_blank.paste(im1,(5,7),im1)\n",
    "#     img_blank.paste(im1,(45,55),im1)\n",
    "#     img_blank.paste(im1,(25,72),im1)\n",
    "#     img_blank.paste(im2,(50,90),im2)\n",
    "#     img_blank.paste(im2,(60,75),im2)\n",
    "#     img_blank.paste(im2,(30,40),im2)\n",
    "#     img_blank.paste(im3,(10,60),im3)\n",
    "#     img_blank.paste(im3,(44,62),im3)\n",
    "#     img_blank.paste(im3,(30,15),im3)\n",
    "    img_blank.paste(imt.rotate(180),(10,30),imt.rotate(180))\n",
    "    \n",
    "    uframes.append(img_blank)\n",
    "    \n",
    "    #only drone\n",
    "    img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "#     img_blank.paste(im1,(5,7),im1)\n",
    "#     img_blank.paste(im1,(45,55),im1)\n",
    "#     img_blank.paste(im1,(25,72),im1)\n",
    "#     img_blank.paste(im2,(50,90),im2)\n",
    "#     img_blank.paste(im2,(60,75),im2)\n",
    "#     img_blank.paste(im2,(30,40),im2)\n",
    "#     img_blank.paste(im3,(10,60),im3)\n",
    "#     img_blank.paste(im3,(44,62),im3)\n",
    "#     img_blank.paste(im3,(30,15),im3)\n",
    "    img_blank.paste(im_drone.resize((10,10)),(2,10),im_drone.resize((10,10)))\n",
    "    \n",
    "    uframes.append(img_blank)\n",
    "    \n",
    "    #t1d1\n",
    "    img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "#     img_blank.paste(im1,(5,7),im1)\n",
    "#     img_blank.paste(im1,(45,55),im1)\n",
    "#     img_blank.paste(im1,(25,72),im1)\n",
    "#     img_blank.paste(im2,(50,90),im2)\n",
    "#     img_blank.paste(im2,(60,75),im2)\n",
    "#     img_blank.paste(im2,(30,40),im2)\n",
    "#     img_blank.paste(im3,(10,60),im3)\n",
    "#     img_blank.paste(im3,(44,62),im3)\n",
    "#     img_blank.paste(im3,(30,15),im3)\n",
    "    img_blank.paste(imt.rotate(180),(10,30),imt.rotate(180))\n",
    "    img_blank.paste(im_drone.resize((10,10)),(2,10),im_drone.resize((10,10)))\n",
    "    \n",
    "    uframes.append(img_blank)\n",
    "    \n",
    "    #t2d1\n",
    "    img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "    img_blank.paste(im1,(5,7),im1)\n",
    "    img_blank.paste(im1,(45,55),im1)\n",
    "    img_blank.paste(im1,(25,72),im1)\n",
    "    img_blank.paste(im2,(50,90),im2)\n",
    "    img_blank.paste(im2,(60,75),im2)\n",
    "    img_blank.paste(im2,(30,40),im2)\n",
    "    img_blank.paste(im3,(10,60),im3)\n",
    "    img_blank.paste(im3,(44,62),im3)\n",
    "    img_blank.paste(im3,(30,15),im3)\n",
    "    img_blank.paste(imt.rotate(180),(30,30),imt.rotate(180))\n",
    "    draw = ImageDraw.Draw(img_blank)\n",
    "    draw.ellipse((35,35,38,38), fill=(255, 0, 0))\n",
    "    img_blank.paste(im_drone.resize((10,10)),(2,10),im_drone.resize((10,10)))\n",
    "    \n",
    "    uframes.append(img_blank)\n",
    "    \n",
    "    #t3d1\n",
    "    img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "#     img_blank.paste(im1,(5,7),im1)\n",
    "#     img_blank.paste(im1,(45,55),im1)\n",
    "#     img_blank.paste(im1,(25,72),im1)\n",
    "#     img_blank.paste(im2,(50,90),im2)\n",
    "#     img_blank.paste(im2,(60,75),im2)\n",
    "#     img_blank.paste(im2,(30,40),im2)\n",
    "#     img_blank.paste(im3,(10,60),im3)\n",
    "#     img_blank.paste(im3,(44,62),im3)\n",
    "#     img_blank.paste(im3,(30,15),im3)\n",
    "    img_blank.paste(imt.rotate(180),(50,30),imt.rotate(180))\n",
    "    img_blank.paste(imb.resize((2,2)),(54,40),imb.resize((2,2)))\n",
    "    img_blank.paste(im_drone.resize((10,10)),(2,10),im_drone.resize((10,10)))\n",
    "    \n",
    "    uframes.append(img_blank)\n",
    "    \n",
    "    #t1d2\n",
    "    img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "#     img_blank.paste(im1,(5,7),im1)\n",
    "#     img_blank.paste(im1,(45,55),im1)\n",
    "#     img_blank.paste(im1,(25,72),im1)\n",
    "#     img_blank.paste(im2,(50,90),im2)\n",
    "#     img_blank.paste(im2,(60,75),im2)\n",
    "#     img_blank.paste(im2,(30,40),im2)\n",
    "#     img_blank.paste(im3,(10,60),im3)\n",
    "#     img_blank.paste(im3,(44,62),im3)\n",
    "#     img_blank.paste(im3,(30,15),im3)\n",
    "    img_blank.paste(imt.rotate(180),(10,30),imt.rotate(180))\n",
    "    img_blank.paste(im_drone.resize((10,10)),(35,45),im_drone.resize((10,10)))\n",
    "    draw = ImageDraw.Draw(img_blank)\n",
    "    draw.ellipse((40,50,43,53), fill=(50, 182, 150))\n",
    "    \n",
    "    uframes.append(img_blank)\n",
    "    \n",
    "    #t2d2\n",
    "    img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "#     img_blank.paste(im1,(5,7),im1)\n",
    "#     img_blank.paste(im1,(45,55),im1)\n",
    "#     img_blank.paste(im1,(25,72),im1)\n",
    "#     img_blank.paste(im2,(50,90),im2)\n",
    "#     img_blank.paste(im2,(60,75),im2)\n",
    "#     img_blank.paste(im2,(30,40),im2)\n",
    "#     img_blank.paste(im3,(10,60),im3)\n",
    "#     img_blank.paste(im3,(44,62),im3)\n",
    "#     img_blank.paste(im3,(30,15),im3)\n",
    "    img_blank.paste(imt.rotate(180),(30,30),imt.rotate(180))\n",
    "    draw = ImageDraw.Draw(img_blank)\n",
    "    draw.ellipse((35,35,38,38), fill=(255, 0, 0))\n",
    "    img_blank.paste(im_drone.resize((10,10)),(35,45),im_drone.resize((10,10)))\n",
    "    draw.ellipse((40,50,43,53), fill=(50, 182, 150))\n",
    "    \n",
    "    \n",
    "    uframes.append(img_blank)\n",
    "    \n",
    "    #t3d2\n",
    "    img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "#     img_blank.paste(im1,(5,7),im1)\n",
    "#     img_blank.paste(im1,(45,55),im1)\n",
    "#     img_blank.paste(im1,(25,72),im1)\n",
    "#     img_blank.paste(im2,(50,90),im2)\n",
    "#     img_blank.paste(im2,(60,75),im2)\n",
    "#     img_blank.paste(im2,(30,40),im2)\n",
    "#     img_blank.paste(im3,(10,60),im3)\n",
    "#     img_blank.paste(im3,(44,62),im3)\n",
    "#     img_blank.paste(im3,(30,15),im3)\n",
    "    img_blank.paste(imt.rotate(180),(50,30),imt.rotate(180))\n",
    "    img_blank.paste(imb.resize((2,2)),(54,40),imb.resize((2,2)))\n",
    "    img_blank.paste(im_drone.resize((10,10)),(35,45),im_drone.resize((10,10)))\n",
    "    draw = ImageDraw.Draw(img_blank)\n",
    "    draw.ellipse((40,50,43,53), fill=(50, 182, 150))\n",
    "    \n",
    "    \n",
    "    uframes.append(img_blank)\n",
    "    \n",
    "    #t1d3\n",
    "    img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "#     img_blank.paste(im1,(5,7),im1)\n",
    "#     img_blank.paste(im1,(45,55),im1)\n",
    "#     img_blank.paste(im1,(25,72),im1)\n",
    "#     img_blank.paste(im2,(50,90),im2)\n",
    "#     img_blank.paste(im2,(60,75),im2)\n",
    "#     img_blank.paste(im2,(30,40),im2)\n",
    "#     img_blank.paste(im3,(10,60),im3)\n",
    "#     img_blank.paste(im3,(44,62),im3)\n",
    "#     img_blank.paste(im3,(30,15),im3)\n",
    "    img_blank.paste(imt.rotate(180),(10,30),imt.rotate(180))\n",
    "    img_blank.paste(im_drone.resize((10,10)),(50,70),im_drone.resize((10,10)))\n",
    "    img_blank.paste(imb.resize((2,2)),(56,81),imb.resize((2,2)))\n",
    "    \n",
    "    uframes.append(img_blank)\n",
    "    \n",
    "    #t2d3\n",
    "    img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "#     img_blank.paste(im1,(5,7),im1)\n",
    "#     img_blank.paste(im1,(45,55),im1)\n",
    "#     img_blank.paste(im1,(25,72),im1)\n",
    "#     img_blank.paste(im2,(50,90),im2)\n",
    "#     img_blank.paste(im2,(60,75),im2)\n",
    "#     img_blank.paste(im2,(30,40),im2)\n",
    "#     img_blank.paste(im3,(10,60),im3)\n",
    "#     img_blank.paste(im3,(44,62),im3)\n",
    "#     img_blank.paste(im3,(30,15),im3)\n",
    "    img_blank.paste(imt.rotate(180),(30,30),imt.rotate(180))\n",
    "    draw = ImageDraw.Draw(img_blank)\n",
    "    draw.ellipse((35,35,38,38), fill=(255, 0, 0))\n",
    "    img_blank.paste(im_drone.resize((10,10)),(50,70),im_drone.resize((10,10)))\n",
    "    img_blank.paste(imb.resize((2,2)),(56,81),imb.resize((2,2)))\n",
    "    \n",
    "    \n",
    "    uframes.append(img_blank)\n",
    "    \n",
    "    #t3d3\n",
    "    img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "#     img_blank.paste(im1,(5,7),im1)\n",
    "#     img_blank.paste(im1,(45,55),im1)\n",
    "#     img_blank.paste(im1,(25,72),im1)\n",
    "#     img_blank.paste(im2,(50,90),im2)\n",
    "#     img_blank.paste(im2,(60,75),im2)\n",
    "#     img_blank.paste(im2,(30,40),im2)\n",
    "#     img_blank.paste(im3,(10,60),im3)\n",
    "#     img_blank.paste(im3,(44,62),im3)\n",
    "#     img_blank.paste(im3,(30,15),im3)\n",
    "    img_blank.paste(imt.rotate(180),(50,30),imt.rotate(180))\n",
    "    img_blank.paste(imb.resize((2,2)),(54,40),imb.resize((2,2)))\n",
    "    img_blank.paste(im_drone.resize((10,10)),(50,70),im_drone.resize((10,10)))\n",
    "    img_blank.paste(imb.resize((2,2)),(56,81),imb.resize((2,2)))\n",
    "    \n",
    "    \n",
    "    uframes.append(img_blank)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(samples):\n",
    "    data1.append(np.array(np.transpose(np.asarray(uframes[i % len(uframes)]),(2,0,1)),dtype=np.float32))\n",
    "    data2.append(np.array(np.transpose(np.asarray(uframes[(i+1) % len(uframes)]),(2,0,1)),dtype=np.float32))\n",
    "\n",
    "\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%% Noisy data\n",
    "img = Image.new('RGB', (100,100), color = '#9b7653')\n",
    "img.paste(im1,(5,75),im1)\n",
    "img.paste(im1,(10,55),im1)\n",
    "img.paste(im1,(25,50),im1)\n",
    "img.paste(im2,(75,5),im2)\n",
    "img.paste(im2,(60,30),im2)\n",
    "img.paste(im2,(90,20),im2)\n",
    "img.paste(im3,(75,60),im3)\n",
    "img.paste(im3,(60,80),im3)\n",
    "im_n = np.reshape(img,(100,100,3))\n",
    "b = np.asarray(im_n)\n",
    "b = np.array(b, dtype=np.float32)\n",
    "b = np.transpose(b,(2,0,1))\n",
    "b = torch.from_numpy(b)\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%       \n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% - Data Preparation\n",
    "\n",
    "y0 = np.asarray(data1)\n",
    "y1 = np.asarray(data2)\n",
    "\n",
    "#y0 = np.array(np.transpose(np.asarray(y0),(0,3,1,2)),dtype=np.float32)\n",
    "#y1 = np.array(np.transpose(np.asarray(y1),(0,3,1,2)),dtype=np.float32)\n",
    "print(np.shape(y0))\n",
    "\n",
    "x = torch.from_numpy(y0)\n",
    "y = torch.from_numpy(y1)\n",
    "\n",
    "\n",
    "torch_dataset = Data.TensorDataset(x,y)\n",
    "\n",
    "\n",
    "loader = Data.DataLoader(\n",
    "\n",
    "    dataset=torch_dataset,\n",
    "\n",
    "    batch_size=Batch_Size,\n",
    "\n",
    "    shuffle=True,\n",
    "\n",
    "    num_workers=0,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% - Defining NN\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=5, stride=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Max pool 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=5)\n",
    "\n",
    "#         # Convolution 2\n",
    "#         self.cnn2 = nn.Conv2d(in_channels=16, out_channels=3, kernel_size=5, stride=1, padding=2)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "\n",
    "#         # Max pool 2\n",
    "#         self.maxpool2 = nn.MaxPool2d(kernel_size=5)\n",
    "\n",
    "        # Fully connected 1 (readout)\n",
    "        self.fc1 = nn.Linear(1083, 15)\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        # Max pool 1\n",
    "        out = self.maxpool1(out)\n",
    "\n",
    "        # Convolution 2 \n",
    "        #out = self.cnn2(out)\n",
    "        #out = self.relu2(out)\n",
    "\n",
    "        # Max pool 2 \n",
    "        #out = self.maxpool2(out)\n",
    "        im_out = out\n",
    "        # Resize\n",
    "        # Original size: (100, 32, 7, 7)\n",
    "        # out.size(0): 100\n",
    "        # New out size: (100, 32*7*7)\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        # Linear function (readout)\n",
    "        out = self.fc1(out)\n",
    "        out = self.sigmoid1(out)\n",
    "        return im_out,out\n",
    "    \n",
    "model = CNNModel()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% - Loss Function\n",
    "\n",
    "def h_score(fx, gy):\n",
    " \n",
    "    fx = fx - fx.mean(0)\n",
    "\n",
    "    gy = gy - gy.mean(0)\n",
    "\n",
    "    Nsamples = fx.size(0)\n",
    "    #print(fx, np.shape(fx))\n",
    "    #print(gy, np.shape(gy))\n",
    "    #print(np.shape((torch.transpose(fx,3,2))),np.shape(fx))\n",
    "    covf = torch.matmul(fx.t(), fx) / Nsamples\n",
    "\n",
    "    covg = torch.matmul(gy.t(), gy) / Nsamples\n",
    "\n",
    "    h = -2 * torch.mean((fx * gy).sum(1)) + (covf * covg).sum()\n",
    "\n",
    "    return h\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for x,y in loader:\n",
    "        optimizer.zero_grad()\n",
    "        # ===================forward=====================\n",
    "        #loss = criterion(output1, img)\n",
    "        loss = h_score(model(x)[1],model(y)[1])\n",
    "        # ===================backward====================\n",
    " \n",
    "        #optimizer_1.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #optimizer_1.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "    print(\"shape: \", np.shape(model(x[0].reshape(1,3,100, 100))[0]))\n",
    "#     print(\"x: \", model(x[0].reshape(1,3,100, 100)))\n",
    "#     print(\"y:\", model(y[0].reshape(1,3,100, 100)))\n",
    "#     print(\"b:\", model(b.reshape(1,3,100, 100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "for i in range(12):\n",
    "    k = uframes[i]\n",
    "    k.show()\n",
    "    v = np.array(np.transpose(np.asarray(uframes[i]),(2,0,1)),dtype=np.float32)\n",
    "    v = torch.from_numpy(v)\n",
    "    filename = \"Testing features-Copy4/ref_image_new_\" + str(i) + \".txt\"\n",
    "    file = open(filename, 'w')\n",
    "    file.write(str(model(v.reshape(1,3,100, 100))[0].detach().numpy()))\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "\n",
    "img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "# img_blank.paste(im1,(5,7),im1)\n",
    "# img_blank.paste(im1,(45,55),im1)\n",
    "# img_blank.paste(im1,(25,72),im1)\n",
    "# img_blank.paste(im2,(50,90),im2)\n",
    "# img_blank.paste(im2,(60,75),im2)\n",
    "# img_blank.paste(im2,(30,40),im2)\n",
    "# img_blank.paste(im3,(10,60),im3)\n",
    "# img_blank.paste(im3,(44,62),im3)\n",
    "# img_blank.paste(im3,(30,15),im3)\n",
    "pil = np.array(np.transpose(np.asarray(img_blank),(2,0,1)),dtype=np.float32)\n",
    "pil = torch.from_numpy(pil)\n",
    "filename = \"Testing features-Copy4/only_background.txt\"\n",
    "file = open(filename, 'w')\n",
    "file.write(str(model(pil.reshape(1,3,100, 100))[0].detach().numpy()))\n",
    "file.close()\n",
    "\n",
    "#t1\n",
    "img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "# img_blank.paste(im1,(5,7),im1)\n",
    "# img_blank.paste(im1,(45,55),im1)\n",
    "# img_blank.paste(im1,(25,72),im1)\n",
    "# img_blank.paste(im2,(50,90),im2)\n",
    "# img_blank.paste(im2,(60,75),im2)\n",
    "# img_blank.paste(im2,(30,40),im2)\n",
    "# img_blank.paste(im3,(10,60),im3)\n",
    "# img_blank.paste(im3,(44,62),im3)\n",
    "# img_blank.paste(im3,(30,15),im3)\n",
    "img_blank.paste(imt.rotate(180),(10,30),imt.rotate(180))\n",
    "pil = np.array(np.transpose(np.asarray(img_blank),(2,0,1)),dtype=np.float32)\n",
    "pil = torch.from_numpy(pil)\n",
    "filename = \"Testing features-Copy4/tank_pos_1.txt\"\n",
    "file = open(filename, 'w')\n",
    "file.write(str(model(pil.reshape(1,3,100, 100))[0].detach().numpy()))\n",
    "file.close()\n",
    "\n",
    "\n",
    "#d1\n",
    "img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "# img_blank.paste(im1,(5,7),im1)\n",
    "# img_blank.paste(im1,(45,55),im1)\n",
    "# img_blank.paste(im1,(25,72),im1)\n",
    "# img_blank.paste(im2,(50,90),im2)\n",
    "# img_blank.paste(im2,(60,75),im2)\n",
    "# img_blank.paste(im2,(30,40),im2)\n",
    "# img_blank.paste(im3,(10,60),im3)\n",
    "# img_blank.paste(im3,(44,62),im3)\n",
    "# img_blank.paste(im3,(30,15),im3)\n",
    "img_blank.paste(im_drone.resize((10,10)),(2,10),im_drone.resize((10,10)))\n",
    "pil = np.array(np.transpose(np.asarray(img_blank),(2,0,1)),dtype=np.float32)\n",
    "pil = torch.from_numpy(pil)\n",
    "filename = \"Testing features-Copy4/drone_pos_1.txt\"\n",
    "file = open(filename, 'w')\n",
    "file.write(str(model(pil.reshape(1,3,100, 100))[0].detach().numpy()))\n",
    "file.close()\n",
    "\n",
    "#t2\n",
    "img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "# img_blank.paste(im1,(5,7),im1)\n",
    "# img_blank.paste(im1,(45,55),im1)\n",
    "# img_blank.paste(im1,(25,72),im1)\n",
    "# img_blank.paste(im2,(50,90),im2)\n",
    "# img_blank.paste(im2,(60,75),im2)\n",
    "# img_blank.paste(im2,(30,40),im2)\n",
    "# img_blank.paste(im3,(10,60),im3)\n",
    "# img_blank.paste(im3,(44,62),im3)\n",
    "# img_blank.paste(im3,(30,15),im3)\n",
    "img_blank.paste(imt.rotate(180),(30,30),imt.rotate(180))\n",
    "draw = ImageDraw.Draw(img_blank)\n",
    "draw.ellipse((30,30,38,38), fill=(255, 0, 0))\n",
    "pil = np.array(np.transpose(np.asarray(img_blank),(2,0,1)),dtype=np.float32)\n",
    "pil = torch.from_numpy(pil)\n",
    "filename = \"Testing features-Copy4/tank_pos_2.txt\"\n",
    "file = open(filename, 'w')\n",
    "file.write(str(model(pil.reshape(1,3,100, 100))[0].detach().numpy()))\n",
    "file.close()\n",
    "\n",
    "\n",
    "#t2_without\n",
    "img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "# img_blank.paste(im1,(5,7),im1)\n",
    "# img_blank.paste(im1,(45,55),im1)\n",
    "# img_blank.paste(im1,(25,72),im1)\n",
    "# img_blank.paste(im2,(50,90),im2)\n",
    "# img_blank.paste(im2,(60,75),im2)\n",
    "# img_blank.paste(im2,(30,40),im2)\n",
    "# img_blank.paste(im3,(10,60),im3)\n",
    "# img_blank.paste(im3,(44,62),im3)\n",
    "# img_blank.paste(im3,(30,15),im3)\n",
    "img_blank.paste(imt.rotate(180),(30,30),imt.rotate(180))\n",
    "pil = np.array(np.transpose(np.asarray(img_blank),(2,0,1)),dtype=np.float32)\n",
    "pil = torch.from_numpy(pil)\n",
    "filename = \"Testing features-Copy4/tank_pos_2_without.txt\"\n",
    "file = open(filename, 'w')\n",
    "file.write(str(model(pil.reshape(1,3,100, 100))[0].detach().numpy()))\n",
    "file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#d2\n",
    "img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "# img_blank.paste(im1,(5,7),im1)\n",
    "# img_blank.paste(im1,(45,55),im1)\n",
    "# img_blank.paste(im1,(25,72),im1)\n",
    "# img_blank.paste(im2,(50,90),im2)\n",
    "# img_blank.paste(im2,(60,75),im2)\n",
    "# img_blank.paste(im2,(30,40),im2)\n",
    "# img_blank.paste(im3,(10,60),im3)\n",
    "# img_blank.paste(im3,(44,62),im3)\n",
    "# img_blank.paste(im3,(30,15),im3)\n",
    "img_blank.paste(im_drone.resize((10,10)),(35,45),im_drone.resize((10,10)))\n",
    "draw = ImageDraw.Draw(img_blank)\n",
    "draw.ellipse((35,45,43,53), fill=(50, 182, 150))\n",
    "pil = np.array(np.transpose(np.asarray(img_blank),(2,0,1)),dtype=np.float32)\n",
    "pil = torch.from_numpy(pil)\n",
    "filename = \"Testing features-Copy4/drone_pos_2.txt\"\n",
    "file = open(filename, 'w')\n",
    "file.write(str(model(pil.reshape(1,3,100, 100))[0].detach().numpy()))\n",
    "file.close()\n",
    "\n",
    "\n",
    "#d2_without\n",
    "img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "# img_blank.paste(im1,(5,7),im1)\n",
    "# img_blank.paste(im1,(45,55),im1)\n",
    "# img_blank.paste(im1,(25,72),im1)\n",
    "# img_blank.paste(im2,(50,90),im2)\n",
    "# img_blank.paste(im2,(60,75),im2)\n",
    "# img_blank.paste(im2,(30,40),im2)\n",
    "# img_blank.paste(im3,(10,60),im3)\n",
    "# img_blank.paste(im3,(44,62),im3)\n",
    "# img_blank.paste(im3,(30,15),im3)\n",
    "img_blank.paste(im_drone.resize((10,10)),(35,45),im_drone.resize((10,10)))\n",
    "pil = np.array(np.transpose(np.asarray(img_blank),(2,0,1)),dtype=np.float32)\n",
    "pil = torch.from_numpy(pil)\n",
    "filename = \"Testing features-Copy4/drone_pos_2_without.txt\"\n",
    "file = open(filename, 'w')\n",
    "file.write(str(model(pil.reshape(1,3,100, 100))[0].detach().numpy()))\n",
    "file.close()\n",
    "\n",
    "\n",
    "\n",
    "#t3\n",
    "img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "# img_blank.paste(im1,(5,7),im1)\n",
    "# img_blank.paste(im1,(45,55),im1)\n",
    "# img_blank.paste(im1,(25,72),im1)\n",
    "# img_blank.paste(im2,(50,90),im2)\n",
    "# img_blank.paste(im2,(60,75),im2)\n",
    "# img_blank.paste(im2,(30,40),im2)\n",
    "# img_blank.paste(im3,(10,60),im3)\n",
    "# img_blank.paste(im3,(44,62),im3)\n",
    "# img_blank.paste(im3,(30,15),im3)\n",
    "img_blank.paste(imt.rotate(180),(50,30),imt.rotate(180))\n",
    "img_blank.paste(imb.resize((2,2)),(54,40),imb.resize((2,2)))\n",
    "pil = np.array(np.transpose(np.asarray(img_blank),(2,0,1)),dtype=np.float32)\n",
    "pil = torch.from_numpy(pil)\n",
    "filename = \"Testing features-Copy4/tank_pos_3.txt\"\n",
    "file = open(filename, 'w')\n",
    "file.write(str(model(pil.reshape(1,3,100, 100))[0].detach().numpy()))\n",
    "file.close()\n",
    "\n",
    "\n",
    "#t3_without\n",
    "img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "# img_blank.paste(im1,(5,7),im1)\n",
    "# img_blank.paste(im1,(45,55),im1)\n",
    "# img_blank.paste(im1,(25,72),im1)\n",
    "# img_blank.paste(im2,(50,90),im2)\n",
    "# img_blank.paste(im2,(60,75),im2)\n",
    "# img_blank.paste(im2,(30,40),im2)\n",
    "# img_blank.paste(im3,(10,60),im3)\n",
    "# img_blank.paste(im3,(44,62),im3)\n",
    "# img_blank.paste(im3,(30,15),im3)\n",
    "img_blank.paste(imt.rotate(180),(50,30),imt.rotate(180))\n",
    "pil = np.array(np.transpose(np.asarray(img_blank),(2,0,1)),dtype=np.float32)\n",
    "pil = torch.from_numpy(pil)\n",
    "filename = \"Testing features-Copy4/tank_pos_3_without.txt\"\n",
    "file = open(filename, 'w')\n",
    "file.write(str(model(pil.reshape(1,3,100, 100))[0].detach().numpy()))\n",
    "file.close()\n",
    "\n",
    "#d3\n",
    "img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "# img_blank.paste(im1,(5,7),im1)\n",
    "# img_blank.paste(im1,(45,55),im1)\n",
    "# img_blank.paste(im1,(25,72),im1)\n",
    "# img_blank.paste(im2,(50,90),im2)\n",
    "# img_blank.paste(im2,(60,75),im2)\n",
    "# img_blank.paste(im2,(30,40),im2)\n",
    "# img_blank.paste(im3,(10,60),im3)\n",
    "# img_blank.paste(im3,(44,62),im3)\n",
    "# img_blank.paste(im3,(30,15),im3)\n",
    "img_blank.paste(im_drone.resize((10,10)),(50,70),im_drone.resize((10,10)))\n",
    "img_blank.paste(imb.resize((2,2)),(56,81),imb.resize((2,2)))\n",
    "pil = np.array(np.transpose(np.asarray(img_blank),(2,0,1)),dtype=np.float32)\n",
    "pil = torch.from_numpy(pil)\n",
    "filename = \"Testing features-Copy4/drone_pos_3.txt\"\n",
    "file = open(filename, 'w')\n",
    "file.write(str(model(pil.reshape(1,3,100, 100))[0].detach().numpy()))\n",
    "file.close()\n",
    "\n",
    "#d3_without\n",
    "img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "# img_blank.paste(im1,(5,7),im1)\n",
    "# img_blank.paste(im1,(45,55),im1)\n",
    "# img_blank.paste(im1,(25,72),im1)\n",
    "# img_blank.paste(im2,(50,90),im2)\n",
    "# img_blank.paste(im2,(60,75),im2)\n",
    "# img_blank.paste(im2,(30,40),im2)\n",
    "# img_blank.paste(im3,(10,60),im3)\n",
    "# img_blank.paste(im3,(44,62),im3)\n",
    "# img_blank.paste(im3,(30,15),im3)\n",
    "img_blank.paste(im_drone.resize((10,10)),(50,70),im_drone.resize((10,10)))\n",
    "pil = np.array(np.transpose(np.asarray(img_blank),(2,0,1)),dtype=np.float32)\n",
    "pil = torch.from_numpy(pil)\n",
    "filename = \"Testing features-Copy4/drone_pos_3_without.txt\"\n",
    "file = open(filename, 'w')\n",
    "file.write(str(model(pil.reshape(1,3,100, 100))[0].detach().numpy()))\n",
    "file.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "1\n",
      "100\n",
      "2\n",
      "150\n",
      "3\n",
      "200\n",
      "4\n",
      "250\n",
      "5\n",
      "300\n",
      "6\n",
      "350\n",
      "7\n",
      "400\n",
      "8\n",
      "450\n",
      "9\n",
      "500\n",
      "10\n",
      "550\n",
      "11\n",
      "600\n",
      "length  600\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "p=0\n",
    "class_data = []\n",
    "while(p<len(uframes)):\n",
    "    data3=[]\n",
    "    print(p)\n",
    "    for i in range(50):\n",
    "        img = uframes[p]\n",
    "        data3.append(np.array(np.transpose(np.asarray(img),(2,0,1)),dtype=np.float32))\n",
    "        y3 = np.array(data3)\n",
    "        x_1 = torch.from_numpy(y3)\n",
    "        temp = model(x_1[i].reshape(1,3,100,100))[1]\n",
    "        #print(temp)\n",
    "        class_data.append((list(temp.detach().numpy()[0]),p))\n",
    "    p+=1\n",
    "    print(len(class_data))\n",
    "\n",
    "random.shuffle(class_data)\n",
    "random.shuffle(class_data)\n",
    "\n",
    "print(\"length \", len(class_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 3)\n",
      "Length of Class data:  600\n",
      "Start\n",
      "(100, 100, 3)\n",
      "[[2.6450168e-02 3.5266244e-01 9.9999344e-01 9.9997008e-01 9.7970641e-01\n",
      "  4.2078169e-03 9.9989879e-01 9.9992383e-01 7.2377011e-06 7.1692616e-01\n",
      "  4.2084229e-04 9.9968994e-01 7.1787596e-01 6.2610768e-04 3.5274121e-01]]\n",
      "Just Background\n",
      "(100, 100, 3)\n",
      "[[5.3903127e-01 2.0649296e-04 9.7816730e-01 9.9718177e-01 9.8071313e-01\n",
      "  5.1724887e-01 9.7145003e-01 9.9350560e-01 4.9213778e-02 2.1393424e-01\n",
      "  4.6548494e-03 9.9550819e-01 2.1496618e-01 7.2685489e-03 1.6307845e-04]]\n",
      "Only Tank moving\n",
      "(100, 100, 3)\n",
      "[[9.9012041e-01 6.9292887e-06 5.5528396e-01 9.9773407e-01 8.3467788e-01\n",
      "  9.9942017e-01 9.9998045e-01 9.9773216e-01 4.1703114e-01 1.8633824e-03\n",
      "  2.2641219e-01 7.2926944e-01 1.8225290e-03 3.6608598e-01 8.3953255e-06]]\n",
      "Only Drone Moving\n",
      "(100, 100, 3)\n",
      "[[9.9976820e-01 2.6269849e-09 3.6737954e-04 8.2336420e-01 8.4171617e-01\n",
      "  9.9999774e-01 9.9436933e-01 8.3677304e-01 9.9980456e-01 2.0057226e-04\n",
      "  7.6476234e-01 1.5623744e-01 1.9645090e-04 8.7095326e-01 2.5126461e-09]]\n",
      "Drone stationary, Tank Stationary\n",
      "(100, 100, 3)\n",
      "[[4.8059055e-01 1.5429630e-06 3.5210927e-05 3.1439725e-01 9.9997711e-01\n",
      "  9.2659181e-01 9.9999976e-01 3.3123440e-01 9.9999058e-01 5.5623376e-01\n",
      "  9.9999118e-01 3.2177632e-05 5.5639851e-01 9.9997759e-01 2.8382560e-08]]\n",
      "Drone Stationary, Tank Reloading\n",
      "(100, 100, 3)\n",
      "[[4.6906361e-01 8.9107692e-05 4.2164944e-02 6.1735140e-05 9.0097779e-01\n",
      "  9.1405749e-01 9.9999928e-01 1.3428947e-04 9.7644717e-01 9.9997127e-01\n",
      "  6.3237429e-01 2.2163387e-01 9.9997151e-01 7.0559007e-01 8.4284969e-05]]\n",
      "\u001b[31m\"Drone Stationary, Tank Firing\"\u001b[0m\n",
      "(100, 100, 3)\n",
      "[[9.9999988e-01 5.1564618e-04 8.1174521e-06 1.7991839e-05 3.6493084e-01\n",
      "  1.0000000e+00 3.5672894e-09 4.1888128e-05 7.7975911e-01 9.9996316e-01\n",
      "  5.3751510e-09 5.8048362e-01 9.9995339e-01 1.6584525e-01 5.2344927e-04]]\n",
      "Drone reloading, Tank Stationary\n",
      "(100, 100, 3)\n",
      "[[9.9999607e-01 4.0056020e-01 6.0216124e-05 3.7874332e-05 4.3001298e-02\n",
      "  9.9999928e-01 6.8589208e-07 2.9071127e-05 2.8223667e-01 1.0000000e+00\n",
      "  2.3283468e-05 6.0420853e-01 9.9999988e-01 4.9074541e-05 4.0032306e-01]]\n",
      "Drone reloading, Tank Reloading\n",
      "(100, 100, 3)\n",
      "[[9.9967921e-01 9.4594991e-01 9.7137666e-04 2.3830296e-10 4.9576396e-01\n",
      "  9.9979776e-01 2.7785176e-05 1.0974760e-09 2.7890727e-02 1.0000000e+00\n",
      "  2.8440583e-09 6.8028510e-01 1.0000000e+00 6.5944888e-02 9.4614804e-01]]\n",
      "\u001b[31m\"Drone Reloading, Tank Firing\"\u001b[0m\n",
      "(100, 100, 3)\n",
      "[[9.7497648e-01 9.9988997e-01 1.1859082e-02 9.9999964e-01 9.9999511e-01\n",
      "  9.9188238e-01 4.1333400e-03 9.9999928e-01 9.0171809e-05 9.9988449e-01\n",
      "  7.1738893e-01 3.2085115e-01 9.9985969e-01 3.4053769e-02 9.9989355e-01]]\n",
      "\u001b[31m\"Drone Firing, Tank Stationary\"\u001b[0m\n",
      "(100, 100, 3)\n",
      "[[3.9608708e-01 9.9999988e-01 8.1753641e-02 9.9999976e-01 9.9993730e-01\n",
      "  4.4046053e-01 4.4383454e-01 9.9999893e-01 1.0015556e-05 1.0000000e+00\n",
      "  9.9990904e-01 3.4263137e-01 9.9999952e-01 8.7022327e-06 9.9999988e-01]]\n",
      "\u001b[31m\"Drone Firing, Tank Reloading\"\u001b[0m\n",
      "(100, 100, 3)\n",
      "[[7.9170642e-03 1.0000000e+00 5.8974975e-01 9.7082525e-01 9.9999714e-01\n",
      "  2.9646971e-03 9.6999568e-01 9.7340977e-01 7.3078797e-07 1.0000000e+00\n",
      "  5.7321817e-01 4.2078787e-01 1.0000000e+00 1.2364094e-02 1.0000000e+00]]\n",
      "\u001b[31m\"Drone Firing, Tank Firing\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from colorama import init  \n",
    "import time\n",
    "import cv2\n",
    "\n",
    "print(np.shape(uframes[0]))\n",
    "\n",
    "\n",
    "#z  = np.array(np.transpose(np.asarray(z),(2,0,1)),dtype=np.float32)\n",
    "# import some data to play with\n",
    "print(\"Length of Class data: \", len(class_data))\n",
    "# Take the first two features. We could avoid this by using a two-dim dataset\n",
    "X = [(i[0]) for i in class_data]\n",
    "y = [i[1] for i in class_data]\n",
    "#print(X,np.shape(X))\n",
    "#print(y,np.shape(y))\n",
    "# we create an instance of SVM and fit out data. We do not scale our\n",
    "# data since we want to plot the support vectors\n",
    "C = 1.0  # SVM regularization parameter\n",
    "clf = svm.SVC(kernel='linear', C=C)\n",
    "clf = clf.fit(X, y)\n",
    "data3=[]\n",
    "y3=0\n",
    "\n",
    "n1 = \"\\x1b[31m\\\"Drone Stationary, Tank Firing\\\"\\x1b[0m\"\n",
    "n2 = \"\\x1b[31m\\\"Drone Reloading, Tank Firing\\\"\\x1b[0m\"\n",
    "n3 = \"\\x1b[31m\\\"Drone Firing, Tank Stationary\\\"\\x1b[0m\"\n",
    "n4 = \"\\x1b[31m\\\"Drone Firing, Tank Reloading\\\"\\x1b[0m\"\n",
    "n5 = \"\\x1b[31m\\\"Drone Firing, Tank Firing\\\"\\x1b[0m\"\n",
    "\n",
    "names = ['Just Background','Only Tank moving', 'Only Drone Moving', 'Drone stationary, Tank Stationary', 'Drone Stationary, Tank Reloading' ,\n",
    "         n1, 'Drone reloading, Tank Stationary', 'Drone reloading, Tank Reloading', n2 , n3,n4,n5]\n",
    "\n",
    "print(\"Start\")\n",
    "\n",
    "img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "img_blank.paste(im1,(5,7),im1)\n",
    "img_blank.paste(im1,(45,55),im1)\n",
    "img_blank.paste(im1,(25,72),im1)\n",
    "img_blank.paste(im2,(50,90),im2)\n",
    "img_blank.paste(im2,(60,75),im2)\n",
    "img_blank.paste(im2,(30,40),im2)\n",
    "img_blank.paste(im3,(10,60),im3)\n",
    "img_blank.paste(im3,(44,62),im3)\n",
    "img_blank.paste(im3,(30,15),im3)\n",
    "img_blank.paste(imt.rotate(180),(50,30),imt.rotate(180))\n",
    "img_blank.paste(imb.resize((2,2)),(54,40),imb.resize((2,2)))\n",
    "#img_blank.paste(im_drone.resize((10,10)),(50,70),im_drone.resize((10,10)))\n",
    "#img_blank.paste(imb.resize((2,2)),(56,81),imb.resize((2,2)))\n",
    "\n",
    "for i in range(12):\n",
    "    #z = cv2.imread('Images_100/0a.png')\n",
    "    #l = Image.fromarray(z)\n",
    "#     print(\"shape of z\", np.shape(z),type(z))\n",
    "#     #l.show()\n",
    "#     #z  = cv2.resize(z,(100,100))\n",
    "#     img = uframes[i]\n",
    "#     print(np.shape(img))\n",
    "#     img.show()\n",
    "#     data3.append(np.array(np.transpose(np.asarray(uframes[i]),(2,0,1)),dtype=np.float32))\n",
    "#     y3 = np.array(data3)\n",
    "#     x_1 = torch.from_numpy(y3)\n",
    "# #     random_img = random.choice(x)\n",
    "# #     print(\"random\", np.shape(random_img),type(random_img))\n",
    "# #     show = random_img.detach().numpy() * 255\n",
    "# #     show = np.array(np.transpose(show,(1,2,0)),dtype=np.uint8)\n",
    "# #     print(\"show\", np.shape(show),type(show))\n",
    "# #     ms = Image.fromarray(show)\n",
    "# #     ms.show()\n",
    "#     temp = model(x_1[i].reshape(1,3,100,100))[1]\n",
    "#     temp = temp.detach().numpy()\n",
    "#     img_blank.show()\n",
    "#     #print(temp)\n",
    "#     z = clf.predict(temp)\n",
    "#     print(names[z[0]])\n",
    "    img = uframes[i]\n",
    "    print(np.shape(img))\n",
    "    img.show()\n",
    "    #ms = Image.fromarray(z)\n",
    "    #ms.show()\n",
    "    data3.append(np.array(np.transpose(np.asarray(img),(2,0,1)),dtype=np.float32))\n",
    "    y3 = np.array(data3)\n",
    "    x_1 = torch.from_numpy(y3)\n",
    "    temp = model(x_1[i].reshape(1,3,100,100))[1]\n",
    "    temp = temp.detach().numpy()\n",
    "    print(temp)\n",
    "    z = clf.predict(temp)\n",
    "    print(names[z[0]])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(uframes\n",
    "         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "img_blank = Image.new('RGB', (100, 100), color = '#9b7653')\n",
    "# img_blank.paste(im1,(5,7),im1)\n",
    "# img_blank.paste(im1,(45,55),im1)\n",
    "# img_blank.paste(im1,(25,72),im1)\n",
    "# img_blank.paste(im2,(50,90),im2)\n",
    "# img_blank.paste(im2,(60,75),im2)\n",
    "# img_blank.paste(im2,(30,40),im2)\n",
    "# img_blank.paste(im3,(10,60),im3)\n",
    "# img_blank.paste(im3,(44,62),im3)\n",
    "# img_blank.paste(im3,(30,15),im3)\n",
    "img_blank.paste(imt.rotate(180),(60,60),imt.rotate(180))\n",
    "#img_blank.paste(im_drone.resize((10,10)),(10,30),im_drone.resize((10,10)))\n",
    "#img_blank.paste(imt.rotate(180),(30,30),imt.rotate(180))\n",
    "#draw = ImageDraw.Draw(img_blank)\n",
    "#draw.ellipse((60,60,68,68), fill=(255, 0, 0))\n",
    "# img_blank.paste(im_drone.resize((10,10)),(35,45),im_drone.resize((10,10)))\n",
    "#draw = ImageDraw.Draw(img_blank)\n",
    "#draw.ellipse((10,30,18,38), fill=(50, 182, 150))\n",
    "#img_blank.paste(imt.rotate(180),(50,30),imt.rotate(180))\n",
    "#img_blank.paste(imb.resize((2,2)),(54,40),imb.resize((2,2)))\n",
    "#img_blank.paste(im_drone.resize((10,10)),(50,70),im_drone.resize((10,10)))\n",
    "#img_blank.paste(imb.resize((2,2)),(56,81),imb.resize((2,2)))\n",
    "img_blank.show()\n",
    "pil = np.array(np.transpose(np.asarray(img_blank),(2,0,1)),dtype=np.float32)\n",
    "pil = torch.from_numpy(pil)\n",
    "filename = \"Testing features-Copy4/testing.txt\"\n",
    "file = open(filename, 'w')\n",
    "file.write(str(model(pil.reshape(1,3,100, 100))[0].detach().numpy()))\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
