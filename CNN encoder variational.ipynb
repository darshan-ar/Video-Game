{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/100, recon loss = -0.00001037\n",
      "epoch : 2/100, recon loss = 0.00037114\n",
      "epoch : 3/100, recon loss = -0.00048991\n",
      "epoch : 4/100, recon loss = -0.00513173\n",
      "epoch : 5/100, recon loss = -0.06180491\n",
      "epoch : 6/100, recon loss = -0.30113275\n",
      "epoch : 7/100, recon loss = -0.60111449\n",
      "epoch : 8/100, recon loss = -0.92566966\n",
      "epoch : 9/100, recon loss = -1.08656090\n",
      "epoch : 10/100, recon loss = -1.43537042\n",
      "epoch : 11/100, recon loss = -1.58237745\n",
      "epoch : 12/100, recon loss = -1.80057842\n",
      "epoch : 13/100, recon loss = -1.86531052\n",
      "epoch : 14/100, recon loss = -1.93677470\n",
      "epoch : 15/100, recon loss = -2.11085800\n",
      "epoch : 16/100, recon loss = -2.25805878\n",
      "epoch : 17/100, recon loss = -2.40782664\n",
      "epoch : 18/100, recon loss = -2.59677409\n",
      "epoch : 19/100, recon loss = -2.63035960\n",
      "epoch : 20/100, recon loss = -2.75634891\n",
      "epoch : 21/100, recon loss = -2.85311681\n",
      "epoch : 22/100, recon loss = -2.92586933\n",
      "epoch : 23/100, recon loss = -2.94641345\n",
      "epoch : 24/100, recon loss = -3.06577549\n",
      "epoch : 25/100, recon loss = -3.13219414\n",
      "epoch : 26/100, recon loss = -3.11461294\n",
      "epoch : 27/100, recon loss = -3.16979237\n",
      "epoch : 28/100, recon loss = -3.19662182\n",
      "epoch : 29/100, recon loss = -3.25358432\n",
      "epoch : 30/100, recon loss = -3.26743639\n",
      "epoch : 31/100, recon loss = -3.33401628\n",
      "epoch : 32/100, recon loss = -3.38275701\n",
      "epoch : 33/100, recon loss = -3.44047874\n",
      "epoch : 34/100, recon loss = -3.45481870\n",
      "epoch : 35/100, recon loss = -3.52145387\n",
      "epoch : 36/100, recon loss = -3.63691251\n",
      "epoch : 37/100, recon loss = -3.68160856\n",
      "epoch : 38/100, recon loss = -3.70563209\n",
      "epoch : 39/100, recon loss = -3.77841931\n",
      "epoch : 40/100, recon loss = -3.79028431\n",
      "epoch : 41/100, recon loss = -3.90654132\n",
      "epoch : 42/100, recon loss = -3.96065406\n",
      "epoch : 43/100, recon loss = -3.96999885\n",
      "epoch : 44/100, recon loss = -4.02623816\n",
      "epoch : 45/100, recon loss = -3.98799910\n",
      "epoch : 46/100, recon loss = -3.92863490\n",
      "epoch : 47/100, recon loss = -4.01103283\n",
      "epoch : 48/100, recon loss = -4.07615368\n",
      "epoch : 49/100, recon loss = -4.15994917\n",
      "epoch : 50/100, recon loss = -4.20785835\n",
      "epoch : 51/100, recon loss = -4.19245937\n",
      "epoch : 52/100, recon loss = -4.19978301\n",
      "epoch : 53/100, recon loss = -4.24695553\n",
      "epoch : 54/100, recon loss = -4.16721172\n",
      "epoch : 55/100, recon loss = -4.31022679\n",
      "epoch : 56/100, recon loss = -4.33470867\n",
      "epoch : 57/100, recon loss = -4.26885658\n",
      "epoch : 58/100, recon loss = -4.30344454\n",
      "epoch : 59/100, recon loss = -4.28146514\n",
      "epoch : 60/100, recon loss = -4.29036129\n",
      "epoch : 61/100, recon loss = -4.25999618\n",
      "epoch : 62/100, recon loss = -4.27948104\n",
      "epoch : 63/100, recon loss = -4.35141770\n",
      "epoch : 64/100, recon loss = -4.32132478\n",
      "epoch : 65/100, recon loss = -4.33676284\n",
      "epoch : 66/100, recon loss = -4.22492883\n",
      "epoch : 67/100, recon loss = -4.34342367\n",
      "epoch : 68/100, recon loss = -4.37995775\n",
      "epoch : 69/100, recon loss = -4.32741760\n",
      "epoch : 70/100, recon loss = -4.32783481\n",
      "epoch : 71/100, recon loss = -4.35567057\n",
      "epoch : 72/100, recon loss = -4.30954696\n",
      "epoch : 73/100, recon loss = -4.32185070\n",
      "epoch : 74/100, recon loss = -4.37110220\n",
      "epoch : 75/100, recon loss = -4.33361649\n",
      "epoch : 76/100, recon loss = -4.34732372\n",
      "epoch : 77/100, recon loss = -4.30926411\n",
      "epoch : 78/100, recon loss = -4.29769832\n",
      "epoch : 79/100, recon loss = -4.33897015\n",
      "epoch : 80/100, recon loss = -4.33811639\n",
      "epoch : 81/100, recon loss = -4.30804107\n",
      "epoch : 82/100, recon loss = -4.36245940\n",
      "epoch : 83/100, recon loss = -4.41259947\n",
      "epoch : 84/100, recon loss = -4.39874069\n",
      "epoch : 85/100, recon loss = -4.32474827\n",
      "epoch : 86/100, recon loss = -4.38775254\n",
      "epoch : 87/100, recon loss = -4.29529176\n",
      "epoch : 88/100, recon loss = -4.35520913\n",
      "epoch : 89/100, recon loss = -4.34607676\n",
      "epoch : 90/100, recon loss = -4.37125692\n",
      "epoch : 91/100, recon loss = -4.39970405\n",
      "epoch : 92/100, recon loss = -4.31828428\n",
      "epoch : 93/100, recon loss = -4.30698286\n",
      "epoch : 94/100, recon loss = -4.30758879\n",
      "epoch : 95/100, recon loss = -4.35846370\n",
      "epoch : 96/100, recon loss = -4.38435895\n",
      "epoch : 97/100, recon loss = -4.32921509\n",
      "epoch : 98/100, recon loss = -4.35048829\n",
      "epoch : 99/100, recon loss = -4.39299109\n",
      "epoch : 100/100, recon loss = -4.32390978\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.utils.data as Data\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "epochs= 100\n",
    "learning_rate = 1e-4\n",
    "from PIL import  Image,ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data1 = []\n",
    "data2= []\n",
    "\n",
    "for i in range(20000):\n",
    "    img = Image.new('RGB', (32, 32), color = 'white')\n",
    "    row,col,ch= np.shape(img)\n",
    "    mean = 0\n",
    "    var = 1\n",
    "    sigma = var**0.5\n",
    "    gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "    noisy = img + gauss\n",
    "    im2 = Image.fromarray(noisy,'RGB')\n",
    "    r = np.random.randint(1,101)\n",
    "    draw = ImageDraw.Draw(im2)\n",
    "    if r%2==0:\n",
    "        draw.rectangle([9,12,12,15],fill='red',outline='red')\n",
    "        data1.append(np.asarray(im2))\n",
    "    else:\n",
    "        draw.rectangle([21, 12, 24, 15], fill='red', outline='red')\n",
    "        data1.append(np.asarray(im2))\n",
    "\n",
    "\n",
    "\n",
    "for i in range(20000):\n",
    "    img = Image.new('RGB', (32, 32), color = 'white')\n",
    "    row,col,ch= np.shape(img)\n",
    "    mean = 0\n",
    "    var = 1\n",
    "    sigma = var**0.5\n",
    "    gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "    noisy = img + gauss\n",
    "    im2 = Image.fromarray(noisy,'RGB')\n",
    "    r = np.random.randint(1,101)\n",
    "    draw = ImageDraw.Draw(im2)\n",
    "    if r%2==0:\n",
    "        draw.rectangle([21, 12, 24, 15], fill='red', outline='red')\n",
    "        data2.append(np.asarray(im2))\n",
    "    else:\n",
    "        draw.rectangle([9,12,12,15],fill='red',outline='red')\n",
    "        data2.append(np.asarray(im2))\n",
    "\n",
    "\n",
    "y0 = np.array(data1, dtype=np.float32)\n",
    "y1 = np.array(data2, dtype=np.float32)\n",
    "y0 = np.transpose(y0, (0, 3, 2, 1))# This to make channels first for CNN\n",
    "y1 = np.transpose(y1, (0, 3, 2, 1)) \n",
    "\n",
    "\n",
    "x = torch.from_numpy(y0)\n",
    "y = torch.from_numpy(y1)\n",
    "\n",
    "\n",
    "\n",
    "torch_dataset = Data.TensorDataset(x,y)\n",
    "\n",
    "\n",
    "loader = Data.DataLoader(\n",
    "\n",
    "    dataset=torch_dataset,\n",
    "\n",
    "    batch_size=250,\n",
    "\n",
    "    shuffle=True,\n",
    "\n",
    "    num_workers=0,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"CNN.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv_layer = nn.Sequential(\n",
    "\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv Layer block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(p=0.05),\n",
    "\n",
    "            # Conv Layer block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "        \n",
    "        # conv layers\n",
    "        x = self.conv_layer(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # fc layer\n",
    "        x = self.fc_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "#  use gpu if available\n",
    "\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "model = CNN()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "# mean-squared error loss\n",
    "def h_score(fx, gy):\n",
    " \n",
    "    fx = fx - fx.mean(0)\n",
    "\n",
    "    gy = gy - gy.mean(0)\n",
    "\n",
    "    Nsamples = fx.size(0)\n",
    "\n",
    "    covf = torch.matmul((fx.t()), fx) / Nsamples\n",
    "\n",
    "    covg = torch.matmul((gy.t()), (gy)) / Nsamples\n",
    "\n",
    "    h = -2 * torch.mean((fx * gy).sum(1)) + (covf * covg).sum()\n",
    "\n",
    "    return h\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for x,y in loader:\n",
    "        # reshape mini-batch data to [N, 784] matrix\n",
    "        # load it to the active device\n",
    "        #print(batch_features[0].shape)\n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    "        optimizer.zero_grad()\n",
    "        # compute reconstructions        \n",
    "        # compute training reconstruction loss\n",
    "        train_loss = h_score(model(x),model(y))\n",
    "        #train_loss = criterion(model(x),model(y))\n",
    "        # compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss += train_loss.item()\n",
    "    \n",
    "    # compute the epoch training loss\n",
    "    loss = loss / len(loader)\n",
    "    \n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, recon loss = {:.8f}\".format(epoch + 1, epochs,loss))\n",
    "    #print(np.shape(model.encoder_hidden_layer.weight.data),np.shape(model_dec.decoder_output_layer.weight.data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([[ 0.2564, -0.9170, -0.4204, -0.9176, -0.5451,  1.0586, -0.4545, -1.2155,\n",
      "          0.1261, -0.7568]], grad_fn=<AddmmBackward>)\n",
      "y: tensor([[ 0.2618, -0.8505, -0.4062, -0.9135, -0.5245,  1.0455, -0.4824, -1.1826,\n",
      "          0.2019, -0.7294]], grad_fn=<AddmmBackward>)\n",
      "x:  tensor([[ 0.2006, -0.7440, -0.3341, -0.9038, -0.4963,  1.0493, -0.5965, -1.0724,\n",
      "          0.1351, -0.6476]], grad_fn=<AddmmBackward>)\n",
      "y: tensor([[ 0.2653, -0.9275, -0.3849, -0.9667, -0.5870,  1.1170, -0.5546, -1.2390,\n",
      "          0.2306, -0.7902]], grad_fn=<AddmmBackward>)\n",
      "x:  tensor([[ 0.3067, -1.0308, -0.4228, -1.0822, -0.6488,  1.2524, -0.5256, -1.4404,\n",
      "          0.2580, -0.8963]], grad_fn=<AddmmBackward>)\n",
      "y: tensor([[ 0.3277, -0.8375, -0.3105, -0.9817, -0.5107,  1.1314, -0.4314, -1.2997,\n",
      "          0.2884, -0.8345]], grad_fn=<AddmmBackward>)\n",
      "x:  tensor([[ 0.2699, -0.9007, -0.4099, -0.9531, -0.6099,  1.1198, -0.5056, -1.2708,\n",
      "          0.1776, -0.7638]], grad_fn=<AddmmBackward>)\n",
      "y: tensor([[ 0.2573, -0.8342, -0.3113, -0.8117, -0.4590,  0.9654, -0.4830, -1.1048,\n",
      "          0.0361, -0.6871]], grad_fn=<AddmmBackward>)\n",
      "x:  tensor([[ 0.4022,  0.4760,  0.5143,  0.3121, -0.0812, -0.0293, -0.0504, -0.4469,\n",
      "          0.4647,  0.4503]], grad_fn=<AddmmBackward>)\n",
      "y: tensor([[ 0.4049,  0.4424,  0.4891,  0.5782,  0.2156,  0.3634, -0.1802,  0.0064,\n",
      "          0.7188,  0.2354]], grad_fn=<AddmmBackward>)\n",
      "x:  tensor([[ 0.3347, -0.9831, -0.4219, -1.0423, -0.6226,  1.2800, -0.5047, -1.3992,\n",
      "          0.2852, -0.8478]], grad_fn=<AddmmBackward>)\n",
      "y: tensor([[ 0.3019, -0.8759, -0.2980, -0.9652, -0.5280,  1.0722, -0.4724, -1.2339,\n",
      "          0.2123, -0.8656]], grad_fn=<AddmmBackward>)\n",
      "x:  tensor([[-0.4581, -0.4306, -0.0228, -0.3478, -0.0060, -0.6795, -0.0497,  0.2129,\n",
      "         -1.0632, -0.3946]], grad_fn=<AddmmBackward>)\n",
      "y: tensor([[-0.4551, -0.4510, -0.0512, -0.3846,  0.0158, -0.7046, -0.0104,  0.2029,\n",
      "         -1.1215, -0.3490]], grad_fn=<AddmmBackward>)\n",
      "x:  tensor([[-0.3889, -0.3377, -0.0419, -0.2935,  0.0201, -0.5571, -0.0131,  0.1642,\n",
      "         -0.9328, -0.3287]], grad_fn=<AddmmBackward>)\n",
      "y: tensor([[-0.3906, -0.3545, -0.0501, -0.2678,  0.0365, -0.6230,  0.0260,  0.1754,\n",
      "         -0.9597, -0.3326]], grad_fn=<AddmmBackward>)\n",
      "x:  tensor([[ 0.3931,  0.6356,  0.4201, -0.4829, -0.7564, -1.0904,  0.5169, -1.7517,\n",
      "         -0.0847,  0.9859]], grad_fn=<AddmmBackward>)\n",
      "y: tensor([[ 0.4993,  0.5859,  0.3744, -0.6814, -0.8449, -0.9291,  0.5778, -1.6912,\n",
      "         -0.0667,  1.1847]], grad_fn=<AddmmBackward>)\n",
      "x:  tensor([[ 0.0364,  0.0415,  0.2371,  0.0810,  0.1025, -0.1243, -0.1191,  0.0903,\n",
      "         -0.2704, -0.0263]], grad_fn=<AddmmBackward>)\n",
      "y: tensor([[ 0.3805,  0.4394,  0.4713,  0.5074,  0.1998,  0.3204, -0.1967, -0.0104,\n",
      "          0.5894,  0.2538]], grad_fn=<AddmmBackward>)\n",
      "b: tensor([[-0.0801, -0.5121, -0.1828, -0.6021, -0.1718,  0.2164, -0.2864, -0.4607,\n",
      "         -0.3601, -0.4356]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "blank = cv2.imread('blank_32x32.png')\n",
    "b = blank.astype('float32')\n",
    "b = torch.from_numpy(b)\n",
    "\n",
    "for i in range(5,15):\n",
    "    print(\"x: \", model(x[i].reshape(1,3,32,32)))\n",
    "    print(\"y:\", model(y[i].reshape(1,3,32,32)))\n",
    "\n",
    "print(\"b:\", model(b.reshape(1,3,32,32)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
